---
---

@inproceedings{nickl2023memory,
  title={The Memory-Perturbation Equation: Understanding Model's Sensitivity to Data},
  abstract = {Understanding model's sensitivity to its training data is crucial but can also be challenging and costly, especially during training. To simplify such issues, we present the Memory-Perturbation Equation (MPE) which relates model's sensitivity to perturbation in its training data. Derived using Bayesian principles, the MPE unifies existing sensitivity measures, generalizes them to a wide-variety of models and algorithms, and unravels useful properties regarding sensitivities. Our empirical results show that sensitivity estimates obtained during training can be used to faithfully predict generalization on unseen test data. The proposed equation is expected to be useful for future research on robust and adaptive learning.},
  author={Nickl, Peter and Xu, Lu* and Tailor, Dharmesh* and Möllenhoff, Thomas and Khan, Mohammad Emtiyaz},
  booktitle={37th Conference on Neural Information Processing Systems (NeurIPS)},
  month={12},
  year={2023},
  abbr={NeurIPS},
  html={https://openreview.net/forum?id=dqS1GuoG2V},
  pdf={https://arxiv.org/pdf/2310.19273.pdf},
  code={https://github.com/team-approx-bayes/memory-perturbation}
}

@inproceedings{tailor2023exploiting,
  title={Exploiting Inferential Structure in Neural Processes},
  abstract = {Neural Processes (NPs) are appealing due to their ability to perform fast adaptation based on a context set. This set is encoded by a latent variable, which is often assumed to follow a simple distribution. However, in real-word settings, the context set may be drawn from richer distributions having multiple modes, heavy tails, etc. In this work, we provide a framework that allows NPs' latent variable to be given a rich prior defined by a graphical model. These distributional assumptions directly translate into an appropriate aggregation strategy for the context set. Moreover, we describe a message-passing procedure that still allows for end-to-end optimization with stochastic gradients. We demonstrate the generality of our framework by using mixture and Student-t assumptions that yield improvements in function modelling and test-time robustness.},
  author={Tailor, Dharmesh and Khan, Mohammad Emtiyaz and Nalisnick, Eric},
  booktitle={39th Conference on Uncertainty in Artificial Intelligence (UAI)},
  year={2023},
  month={8},
  abbr={UAI},
  html={https://proceedings.mlr.press/v216/tailor23a.html},
  pdf={https://arxiv.org/pdf/2306.15169.pdf},
  code={https://github.com/dvtailor/np-structured-inference}
}

@inproceedings{tailor2023memory,
  title={Memory Maps to Understand Models},
  author={Tailor, Dharmesh and Chang, Paul Edmund and Swaroop, Siddharth and Nalisnick, Eric and Solin, Arno and Khan, Mohammad Emtiyaz},
  booktitle={ICML 2023 Workshop on Principles of Duality for Modern Machine Learning},
  year={2023},
  month={7},
  abbr={DP4ML},
  html={https://dp4ml.github.io/},
}

@inproceedings{tailor2024l2dmeta,
  title={Learning to Defer to a Population: A Meta-Learning Approach},
  abstract = {The learning to defer (L2D) framework allows autonomous systems to be safe and robust by allocating difficult decisions to a human expert. All existing work on L2D assumes that each expert is well-identified, and if any expert were to change, the system should be re-trained. In this work, we alleviate this constraint, formulating an L2D system that can cope with never-before-seen experts at test-time. We accomplish this by using meta-learning, considering both optimization- and model-based variants. Given a small context set to characterize the currently available expert, our framework can quickly adapt its deferral policy. For the model-based approach, we employ an attention mechanism that is able to look for points in the context set that are similar to a given test point, leading to an even more precise assessment of the expert's abilities. In the experiments, we validate our methods on image recognition, traffic sign detection, and skin lesion diagnosis benchmarks.},
  author={Tailor, Dharmesh and Patra, Aditya and Verma, Rajeev and Manggala, Putra and Nalisnick, Eric},
  booktitle={27th International Conference on Artificial Intelligence and Statistics},
  year={2024},
  month={5},
  abbr={AISTATS},
  html={https://proceedings.mlr.press/v238/tailor24a.html},
  pdf={https://arxiv.org/pdf/2403.02683.pdf},
  code={https://github.com/dvtailor/meta-l2d},
}

@inproceedings{tailor2025approxfcp,
  title={Approximating Full Conformal Prediction for Neural Network Regression with Gauss-Newton Influence},
  abstract={Uncertainty quantification is an important prerequisite for the deployment of deep learning models in safety-critical areas. Yet, this hinges on the uncertainty estimates being useful to the extent the predictive prediction intervals are well-calibrated and sharp. In the absence of inherent uncertainty estimates (e.g. pretrained models), popular approaches that operate post-hoc include Laplace’s method and split conformal prediction (split-CP). However, Laplace’s method can be miscalibrated when the model is misspecified and split-CP requires sample splitting, and thus comes at the expense of statistical efficiency. In this work, we construct prediction intervals for neural network regressors post-hoc without held-out data. This is achieved by approximating the full conformal prediction method (full-CP). Whilst full-CP nominally requires retraining the model for every test point and candidate label, we propose to train just once and locally perturb model parameters using Gauss-Newton influence to approximate the effect of retraining. Coupled with linearization of the network, we express the absolute residual nonconformity score as a piecewise linear function of the candidate label allowing for an efficient procedure that avoids the exhaustive search over the output space. On standard regression benchmarks and bounding box localization, we show the resulting prediction intervals are locally-adaptive and often tighter than those of split-CP.},
  author={Tailor, Dharmesh and Correia, Alvaro and Nalisnick, Eric and Louizos, Christos},
  booktitle={13th International Conference on Learning Representations (to appear)},
  year={2025},
  month={4},
  html={https://openreview.net/forum?id=vcX0k4rGTt},
  abbr={ICLR},
}
