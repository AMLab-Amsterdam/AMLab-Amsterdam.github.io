<!DOCTYPE html>
<html lang="en">

  <!-- Head -->
  <head>    <!-- Metadata, OpenGraph and Schema.org -->
    

    <!-- Standard metadata -->
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <title>AMLab  | Amsterdam Machine Learning Lab | Babakesmaeili</title>
    <meta name="author" content="AMLab  | Amsterdam Machine Learning Lab" />
    <meta name="description" content="I am a PhD student at the [Amsterdam Machine Learning Lab](https://amlab.science.uva.nl/) (AMLab) supervised by [Jan-Willem van de Meent](https://jwvdm.github.io/). Before September 2021, I was a PhD student at the [Khoury College of Computer Science](https://www.khoury.northeastern.edu/).

I am interested in deep generative models and how we can guide them towards learning representations that are useful for downstream tasks.
" />
    <meta name="keywords" content="machine learning research" />


    <!-- Bootstrap & MDB -->
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous" />

    <!-- Fonts & Icons -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous">
    <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons">

    <!-- Code Syntax Highlighting -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="none" id="highlight_theme_light" />

    <!-- Styles -->
    
    <link rel="shortcut icon" href="/assets/img/AMLab-logo.svg"/>
    
    <link rel="stylesheet" href="/assets/css/main.css">
    <link rel="canonical" href="https://amlab-amsterdam.github.io/people/BabakEsmaeili/">
    
    <!-- Dark Mode -->
    

  </head>

  <!-- Body -->
  <body class="fixed-top-nav ">

    <!-- Header -->
    <header>

      <!-- Nav Bar -->
      <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top">
        <div class="container">
          <a class="navbar-brand title font-weight-lighter" href="https://AMLab-Amsterdam.github.io/"><span class="font-weight-bold">AMLab</span>   | Amsterdam Machine Learning Lab</a>
          <!-- Navbar Toggle -->
          <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
            <span class="sr-only">Toggle navigation</span>
            <span class="icon-bar top-bar"></span>
            <span class="icon-bar middle-bar"></span>
            <span class="icon-bar bottom-bar"></span>
          </button>

          <div class="collapse navbar-collapse text-right" id="navbarNav">
            <ul class="navbar-nav ml-auto flex-nowrap">

              <!-- About -->
              <!-- <li class="nav-item ">
                <a class="nav-link" href="/">about</a>
              </li> -->
              
              <!-- Blog -->
              <li class="nav-item ">
                <a class="nav-link" href="/blog/">Blog</a>
              </li>

              <!-- Other pages -->
              <li class="nav-item ">
                <a class="nav-link" href="/contact/">Contact</a>
              </li>
              <li class="nav-item ">
                <a class="nav-link" href="/joining/">Joining</a>
              </li>
              <li class="nav-item ">
                <a class="nav-link" href="/people/">People</a>
              </li>
              <li class="nav-item ">
                <a class="nav-link" href="/publications/">Publications</a>
              </li>
            </ul>
          </div>
        </div>
      </nav>
    </header>

    <!-- Content -->
    <div class="container mt-5">
      <!-- person-page.html -->
<div class="post">

<!--   <header class="post-header">
    <h1 class="post-title">BabakEsmaeili.md</h1>
    <p class="post-description">Deep generative models, representation learning, inference</p>
  </header>
 -->
  <article>
    <div class="clearfix">
<div class="person-header">
<div class="person-headshot float-left">
    <figure>

  <picture>
<!--     <source media="(max-width: 480px)" srcset="/assets/img/BabakEsmaeili-480.webp" />
    <source media="(max-width: 800px)" srcset="/assets/img/BabakEsmaeili-800.webp" />
    <source media="(max-width: 1400px)" srcset="/assets/img/BabakEsmaeili-1400.webp" />
    -->
    <!-- Fallback to the original file -->
    <img class="img-fluid rounded z-depth-1" src="/assets/img/BabakEsmaeili.png" title="profile picture">

  </picture>

</figure>

</div>
<div class="person-info">
    <h2>
      Babak
      
      Esmaeili
    </h2>
    <p><b>PhD candidate
    
    (advised by J.W. van de Meent)
    
    </b><br>
    
    AMLab<br>
    
    
    Informatics Institute<br>
    
    
    University of Amsterdam<br>
    
    
    Science Park, Lab 42, L4.22<br>
    
    </p>

    <p>
        <i class="far fa-envelope"></i> <a href="mailto:bchie6AetesmaeilivaraiRi8uvachie6Aetnl" onmouseover="this.href=this.href.replace(/varaiRi8/,'@').replace(/chie6Aet/g,'.').replace(/Oe8eed6M/g,'_').replace(/oaPoo7eo/g,'-')"><span class="o3m41l" data-x="b.esmaeili" data-y="uva.nl"></span></a>
        
    </p>

    
    <i class="far fa-address-card"></i> <a href="https://babak0032.github.io/" title="Work" target="_blank" rel="noopener noreferrer"> Personal page </a>  
         
    
    <i class="ai ai-google-scholar"></i> <a href="https://scholar.google.com/citations?user=cBD6liwAAAAJ" title="Scholar" target="_blank" rel="noopener noreferrer">Google scholar </a> 
    
    
    <i class="fab fa-github"></i> <a href="https://github.com/babak0032" title="GitHub" target="_blank" rel="noopener noreferrer"> Github </a> 
    
     
    
    <i class="fab fa-twitter"></i> <a href="https://twitter.com/bob_smiley_" title="Twitter" target="_blank" rel="noopener noreferrer"> Twitter </a> 
     
</div>

<p>I am a PhD student at the <a href="https://amlab.science.uva.nl/" target="_blank" rel="noopener noreferrer">Amsterdam Machine Learning Lab</a> (AMLab) supervised by <a href="https://jwvdm.github.io/" target="_blank" rel="noopener noreferrer">Jan-Willem van de Meent</a>. Before September 2021, I was a PhD student at the <a href="https://www.khoury.northeastern.edu/" target="_blank" rel="noopener noreferrer">Khoury College of Computer Science</a>.</p>

<p>I am interested in deep generative models and how we can guide them towards learning representations that are useful for downstream tasks.</p>


<br>



</div>


<div class="publications">
<h2>Selected Publications</h2>
<ol class="bibliography">
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge">NeurIPS</abbr></div>

        <!-- Entry bib key -->
        <div id="zimmermann2021nested" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">Nested Variational Inference</div>
          <!-- Author -->
          <div class="author">Zimmermann, Heiko, Wu, Hao, Esmaeili, Babak, and Meent, Jan-Willem
          </div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>In 35th Conference on Neural Information Processing Systems (NeurIPS)</em> Dec 2021
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a href="https://proceedings.neurips.cc/paper/2021/file/ab49b208848abe14418090d95df0d590-Paper.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>We develop nested variational inference (NVI), a family of methods that learn proposals for nested importance samplers by minimizing an forward or reverse KL divergence at each level of nesting. NVI is applicable to many commonly-used importance sampling strategies and provides a mechanism for learning intermediate densities, which can serve as heuristics to guide the sampler. Our experiments apply NVI to (a) sample from a multimodal distribution using a learned annealing path (b) learn heuristics that approximate the likelihood of future observations in a hidden Markov model and (c) to perform amortized inference in hierarchical deep generative models. We observe that optimizing nested objectives leads to improved sample quality in terms of log average weight and effective sample size.</p>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge">ICML</abbr></div>

        <!-- Entry bib key -->
        <div id="pmlr-v139-wu21a" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">Conjugate Energy-Based Models</div>
          <!-- Author -->
          <div class="author">Wu*, Hao, Esmaeili*, Babak, Wick, Michael, Tristan, Jean-Baptiste, and Van De Meent, Jan-Willem
          </div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>In Proceedings of the 38th International Conference on Machine Learning</em> 18–24 jul 2021
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a href="http://proceedings.mlr.press/v139/wu21a/wu21a.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>In this paper, we propose conjugate energy-based models (CEBMs), a new class of energy-based models that define a joint density over data and latent variables. The joint density of a CEBM decomposes into an intractable distribution over data and a tractable posterior over latent variables. CEBMs have similar use cases as variational autoencoders, in the sense that they learn an unsupervised mapping from data to latent variables. However, these models omit a generator network, which allows them to learn more flexible notions of similarity between data points. Our experiments demonstrate that conjugate EBMs achieve competitive results in terms of image modelling, predictive power of latent space, and out-of-domain detection on a variety of datasets.</p>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge">AISTATS</abbr></div>

        <!-- Entry bib key -->
        <div id="bozkurt_rate-regularization_2021" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">Rate-Regularization and Generalization in Variational Autoencoders</div>
          <!-- Author -->
          <div class="author">Bozkurt*, Alican, Esmaeili*, Babak, Tristan, Jean-Baptiste, Brooks, Dana, Dy, Jennifer, and Meent, Jan-Willem van de
          </div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>In Proceedings of The 24th International Conference on Artificial Intelligence and Statistics</em> Mar 2021
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a href="http://proceedings.mlr.press/v130/bozkurt21a/bozkurt21a.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Variational autoencoders (VAEs) optimize an objective that comprises a reconstruction loss (the distortion) and a KL term (the rate). The rate is an upper bound on the mutual information, which is often interpreted as a regularizer that controls the degree of compression. We here examine whether inclusion of the rate term also improves generalization. We perform rate-distortion analyses in which we control the strength of the rate term, the network capacity, and the difficulty of the generalization problem. Lowering the strength of the rate term paradoxically improves generalization in most settings, and reducing the mutual information typically leads to underfitting. Moreover, we show that generalization performance continues to improve even after the mutual information saturates, indicating that the gap on the bound (i.e. the KL divergence relative to the inference marginal) affects generalization. This suggests that the standard spherical Gaussian prior is not an inductive bias that typically improves generalization, prompting further work to understand what choices of priors improve generalization in VAEs.</p>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge">AISTATS</abbr></div>

        <!-- Entry bib key -->
        <div id="esmaeili_structured_2019" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">Structured Disentangled Representations</div>
          <!-- Author -->
          <div class="author">Esmaeili, Babak, Wu, Hao, Jain, Sarthak, Bozkurt, Alican, Siddharth, N., Paige, Brooks, Brooks, Dana H., Dy, Jennifer, and Meent, Jan-Willem
          </div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>In The 22nd International Conference on Artificial Intelligence and Statistics</em> Apr 2019
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a href="https://proceedings.mlr.press/v89/esmaeili19a/esmaeili19a.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Deep latent-variable models learn representations of high-dimensional data in an unsupervised manner. A number of recent efforts have focused on learning representations that disentangle statistically independent axes of variation by introducing modifications to the standard objective function. These approaches generally assume a simple diagonal Gaussian prior and as a result are not able to reliably disentangle discrete factors of variation. We propose a two-level hierarchical objective to control relative degree of statistical independence between blocks of variables and individual variables within blocks. We derive this objective as a generalization of the evidence lower bound, which allows us to explicitly represent the trade-offs between mutual information between data and representation, KL divergence between representation and prior, and coverage of the support of the empirical data distribution. Experiments on a variety of datasets demonstrate that our objective can not only disentangle discrete variables, but that doing so also improves disentanglement of other variables and, importantly, generalization even to unseen combinations of factors.</p>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge">AISTATS</abbr></div>

        <!-- Entry bib key -->
        <div id="esmaeili_structured_2020" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">Structured Neural Topic Models for Reviews</div>
          <!-- Author -->
          <div class="author">Esmaeili, Babak, Huang, Hongyi, Wallace, Byron, and Meent, Jan-Willem van de
          </div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>In Proceedings of the Twenty-Second International Conference on Artificial Intelligence and Statistics</em> Apr 2019
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a href="http://proceedings.mlr.press/v89/esmaeili19b/esmaeili19b.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>We present Variational Aspect-based Latent Topic Allocation (VALTA), a family of autoencoding topic models that learn aspect-based representations of reviews. VALTA defines a user-item encoder that maps bag-of-words vectors for combined reviews associated with each paired user and item onto structured embeddings, which in turn define per-aspect topic weights. We model individual reviews in a structured manner by inferring an aspect assignment for each sentence in a given review, where the per-aspect topic weights obtained by the user-item encoder serve to define a mixture over topics, conditioned on the aspect. The result is an autoencoding neural topic model for reviews, which can be trained in a fully unsupervised manner to learn topics that are structured into aspects. Experimental evaluation on large number of datasets demonstrates that aspects are interpretable, yield higher coherence scores than non-structured autoencoding topic model variants, and can be utilized to perform aspect-based comparison and genre discovery.</p>
          </div>
        </div>
      </div>
</li>
</ol>
</div>
 


</div>

  </article>

</div>

    </div>

    <!-- Footer -->    
    <footer class="fixed-bottom">
      <div class="container mt-0">
        © Copyright 2024 AMLab  | Amsterdam Machine Learning Lab. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="noopener noreferrer">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" target="_blank" rel="noopener noreferrer">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="noopener noreferrer">GitHub Pages</a>.

      </div>
    </footer>

    <!-- JavaScripts -->
    <!-- jQuery -->
  <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script>

    <!-- Bootsrap & MDB scripts -->
  <script src="https://cdn.jsdelivr.net/npm/@popperjs/core@2.11.2/dist/umd/popper.min.js" integrity="sha256-l/1pMF/+J4TThfgARS6KwWrk/egwuVvhRzfLAMQ6Ds4=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.min.js" integrity="sha256-SyTu6CwrfOhaznYZPoolVw2rxoY7lKYKQvqbtqN93HI=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script>

    <!-- Masonry & imagesLoaded -->
  <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script>
  <script defer src="/assets/js/masonry.js" type="text/javascript"></script>
    
  <!-- Medium Zoom JS -->
  <script src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.6/dist/medium-zoom.min.js" integrity="sha256-EdPgYcPk/IIrw7FYeuJQexva49pVRZNmt3LculEr7zM=" crossorigin="anonymous"></script>
  <script src="/assets/js/zoom.js"></script><!-- Load Common JS -->
  <script src="/assets/js/common.js"></script>

    <!-- MathJax -->
  <script type="text/javascript">
    window.MathJax = {
      tex: {
        tags: 'ams'
      }
    };
  </script>
  <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script>
  <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>

    
  </body>
</html>

