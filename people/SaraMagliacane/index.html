<!DOCTYPE html>
<html lang="en">

  <!-- Head -->
  <head>    <!-- Metadata, OpenGraph and Schema.org -->
    

    <!-- Standard metadata -->
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <title>AMLab  | Amsterdam Machine Learning Lab | Saramagliacane</title>
    <meta name="author" content="AMLab  | Amsterdam Machine Learning Lab" />
    <meta name="description" content="I am an assistant professor at the University Amsterdam and a Research Scientist at [MIT-IBM Watson AI lab](https://mitibmwatsonailab.mit.edu/). My group focuses on three directions, causal representation learning, causality-inspired machine learning and how can causality help learn dynamical systems. Causal representation learning is the task of learning causal factors from high-dimensional data, e.g. images. Causality-inspired machine learning is the application of ideas of causal inference to machine learning, especially transfer learning and reinforcement learning. The end goal of my research is to combine these directions to make ML methods robust to distribution shift and adaptable across domains and tasks. I also continue working on my previous research on causal discovery, i.e. learning causal relations from data. 

Previously I was a postdoctoral researcher at IBM Research NY, working on methods to design experiments that would allow one to learn causal relations in a sample-efficient and intervention-efficient way. I received a PhD at the VU Amsterdam on learning causal relations jointly from different experimental settings, especially in the case of latent confounders and small samples. 
" />
    <meta name="keywords" content="machine learning research" />


    <!-- Bootstrap & MDB -->
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous" />

    <!-- Fonts & Icons -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous">
    <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons">

    <!-- Code Syntax Highlighting -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="none" id="highlight_theme_light" />

    <!-- Styles -->
    
    <link rel="shortcut icon" href="/assets/img/AMLab-logo.svg"/>
    
    <link rel="stylesheet" href="/assets/css/main.css">
    <link rel="canonical" href="https://amlab-amsterdam.github.io/people/SaraMagliacane/">
    
    <!-- Dark Mode -->
    

  </head>

  <!-- Body -->
  <body class="fixed-top-nav ">

    <!-- Header -->
    <header>

      <!-- Nav Bar -->
      <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top">
        <div class="container">
          <a class="navbar-brand title font-weight-lighter" href="https://AMLab-Amsterdam.github.io/"><span class="font-weight-bold">AMLab</span>   | Amsterdam Machine Learning Lab</a>
          <!-- Navbar Toggle -->
          <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
            <span class="sr-only">Toggle navigation</span>
            <span class="icon-bar top-bar"></span>
            <span class="icon-bar middle-bar"></span>
            <span class="icon-bar bottom-bar"></span>
          </button>

          <div class="collapse navbar-collapse text-right" id="navbarNav">
            <ul class="navbar-nav ml-auto flex-nowrap">

              <!-- About -->
              <!-- <li class="nav-item ">
                <a class="nav-link" href="/">about</a>
              </li> -->
              
              <!-- Blog -->
              <li class="nav-item ">
                <a class="nav-link" href="/blog/">Blog</a>
              </li>

              <!-- Other pages -->
              <li class="nav-item ">
                <a class="nav-link" href="/contact/">Contact</a>
              </li>
              <li class="nav-item ">
                <a class="nav-link" href="/joining/">Joining</a>
              </li>
              <li class="nav-item ">
                <a class="nav-link" href="/people/">People</a>
              </li>
              <li class="nav-item ">
                <a class="nav-link" href="/publications/">Publications</a>
              </li>
            </ul>
          </div>
        </div>
      </nav>
    </header>

    <!-- Content -->
    <div class="container mt-5">
      <!-- person-page.html -->
<div class="post">

<!--   <header class="post-header">
    <h1 class="post-title">SaraMagliacane.md</h1>
    <p class="post-description">Causality, causal representation learning, causality-inspired ML, dynamical systems</p>
  </header>
 -->
  <article>
    <div class="clearfix">
<div class="person-header">
<div class="person-headshot float-left">
    <figure>

  <picture>
<!--     <source media="(max-width: 480px)" srcset="/assets/img/SaraMagliacane-480.webp" />
    <source media="(max-width: 800px)" srcset="/assets/img/SaraMagliacane-800.webp" />
    <source media="(max-width: 1400px)" srcset="/assets/img/SaraMagliacane-1400.webp" />
    -->
    <!-- Fallback to the original file -->
    <img class="img-fluid rounded z-depth-1" src="/assets/img/SaraMagliacane.jpg" title="profile picture">

  </picture>

</figure>

</div>
<div class="person-info">
    <h2>
      Sara
      
      Magliacane
    </h2>
    <p><b>Assistant professor
    
    </b><br>
    
    AMLab<br>
    
    
    Informatics Institute<br>
    
    
    University of Amsterdam<br>
    
    
    Lab 42, Science Park 900, 1012 WX Amsterdam<br>
    
    </p>

    <p>
        <i class="far fa-envelope"></i> <a href="mailto:schie6AetmagliacanevaraiRi8uvachie6Aetnl" onmouseover="this.href=this.href.replace(/varaiRi8/,'@').replace(/chie6Aet/g,'.').replace(/Oe8eed6M/g,'_').replace(/oaPoo7eo/g,'-')"><span class="o3m41l" data-x="s.magliacane" data-y="uva.nl"></span></a>
        
    </p>

    
    <i class="far fa-address-card"></i> <a href="https://saramagliacane.github.io" title="Work" target="_blank" rel="noopener noreferrer"> Personal page </a>  
         
    
    <i class="ai ai-google-scholar"></i> <a href="https://scholar.google.com/citations?user=H3j_zQ4AAAAJ" title="Scholar" target="_blank" rel="noopener noreferrer">Google scholar </a> 
    
    
    <i class="fab fa-github"></i> <a href="https://github.com/saramagliacane" title="GitHub" target="_blank" rel="noopener noreferrer"> Github </a> 
    
     
    
    <i class="fab fa-twitter"></i> <a href="https://twitter.com/saramagliacane" title="Twitter" target="_blank" rel="noopener noreferrer"> Twitter </a> 
     
</div>

<p>I am an assistant professor at the University Amsterdam and a Research Scientist at <a href="https://mitibmwatsonailab.mit.edu/" target="_blank" rel="noopener noreferrer">MIT-IBM Watson AI lab</a>. My group focuses on three directions, causal representation learning, causality-inspired machine learning and how can causality help learn dynamical systems. Causal representation learning is the task of learning causal factors from high-dimensional data, e.g. images. Causality-inspired machine learning is the application of ideas of causal inference to machine learning, especially transfer learning and reinforcement learning. The end goal of my research is to combine these directions to make ML methods robust to distribution shift and adaptable across domains and tasks. I also continue working on my previous research on causal discovery, i.e. learning causal relations from data.</p>

<p>Previously I was a postdoctoral researcher at IBM Research NY, working on methods to design experiments that would allow one to learn causal relations in a sample-efficient and intervention-efficient way. I received a PhD at the VU Amsterdam on learning causal relations jointly from different experimental settings, especially in the case of latent confounders and small samples.</p>


<br>



</div>


<div class="publications">
<h2>Selected Publications</h2>
<ol class="bibliography">
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge">NeurIPS</abbr></div>

        <!-- Entry bib key -->
        <div id="feng2022factored" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">Factored Adaptation for Non-Stationary Reinforcement Learning</div>
          <!-- Author -->
          <div class="author">Feng, Fan, Huang, Biwei, Zhang, Kun, and Magliacane, Sara
          </div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>In Advances in Neural Information Processing Systems</em>  2022
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a href="https://arxiv.org/abs/2203.16582" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">HTML</a>
            <a href="https://arxiv.org/pdf/2203.16582.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a>
            <a href="https://github.com/ffeng1996/Factored-Nonstationary-RL" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Code</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Dealing with non-stationarity in environments (e.g., in the transition dynamics) and objectives (e.g., in the reward functions) is a challenging problem that is crucial in real-world applications of reinforcement learning (RL). While most current approaches model the changes as a single shared embedding vector, we leverage insights from the recent causality literature to model non-stationarity in terms of individual latent change factors, and causal graphs across different environments. In particular, we propose Factored Adaptation for Non-Stationary RL (FANS-RL), a factored adaption approach that learns jointly both the causal structure in terms of a factored MDP, and a factored representation of the individual time-varying change factors. We prove that under standard assumptions, we can completely recover the causal graph representing the factored transition and reward function, as well as a partial structure between the individual change factors and the state components. Through our general framework, we can consider general non-stationary scenarios with different function types and changing frequency, including changes across episodes and within episodes. Experimental results demonstrate that FANS-RL outperforms existing approaches in terms of return, compactness of the latent state representation, and robustness to varying degrees of non-stationarity.</p>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge">ICML</abbr></div>

        <!-- Entry bib key -->
        <div id="pmlr-v162-lippe22a" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">CITRIS: Causal Identifiability from Temporal Intervened Sequences</div>
          <!-- Author -->
          <div class="author">Lippe, Phillip, Magliacane, Sara, Löwe, Sindy, Asano, Yuki M, Cohen, Taco, and Gavves, Stratis
          </div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>In Proceedings of the 39th International Conference on Machine Learning</em> 17–23 jul 2022
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a href="https://proceedings.mlr.press/v162/lippe22a.html" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">HTML</a>
            <a href="https://proceedings.mlr.press/v162/lippe22a/lippe22a.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a>
            <a href="https://github.com/phlippe/CITRIS" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Code</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Understanding the latent causal factors of a dynamical system from visual observations is considered a crucial step towards agents reasoning in complex environments. In this paper, we propose CITRIS, a variational autoencoder framework that learns causal representations from temporal sequences of images in which underlying causal factors have possibly been intervened upon. In contrast to the recent literature, CITRIS exploits temporality and observing intervention targets to identify scalar and multidimensional causal factors, such as 3D rotation angles. Furthermore, by introducing a normalizing flow, CITRIS can be easily extended to leverage and disentangle representations obtained by already pretrained autoencoders. Extending previous results on scalar causal factors, we prove identifiability in a more general setting, in which only some components of a causal factor are affected by interventions. In experiments on 3D rendered image sequences, CITRIS outperforms previous methods on recovering the underlying causal variables. Moreover, using pretrained autoencoders, CITRIS can even generalize to unseen instantiations of causal factors, opening future research areas in sim-to-real generalization for causal representation learning.</p>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge">ICLR</abbr></div>

        <!-- Entry bib key -->
        <div id="huang2022adarl" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">AdaRL: What, Where, and How to Adapt in Transfer Reinforcement Learning</div>
          <!-- Author -->
          <div class="author">Huang, Biwei, Feng, Fan, Lu, Chaochao, Magliacane, Sara, and Zhang, Kun
          </div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>In International Conference on Learning Representations</em> 17–23 jul 2022
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a href="https://openreview.net/forum?id=8H5bpVwvt5" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">HTML</a>
            <a href="https://openreview.net/pdf?id=8H5bpVwvt5" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a>
            <a href="https://github.com/Adaptive-RL/AdaRL-code" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Code</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>One practical challenge in reinforcement learning (RL) is how to make quick adaptations when faced with new environments. In this paper, we propose a principled framework for adaptive RL, called \textitAdaRL, that adapts reliably and efficiently to changes across domains with a few samples from the target domain, even in partially observable environments. Specifically, we leverage a parsimonious graphical representation that characterizes structural relationships over variables in the RL system. Such graphical representations provide a compact way to encode what and where the changes across domains are, and furthermore inform us with a minimal set of changes that one has to consider for the purpose of policy adaptation. We show that by explicitly leveraging this compact representation to encode changes, we can efficiently adapt the policy to the target domain, in which only a few samples are needed and further policy optimization is avoided. We illustrate the efficacy of AdaRL through a series of experiments that vary factors in the observation, transition, and reward functions for Cartpole and Atari games.</p>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge">NeurIPS</abbr></div>

        <!-- Entry bib key -->
        <div id="squires2022active" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">Active Structure Learning of Causal DAGs via Directed Clique Trees</div>
          <!-- Author -->
          <div class="author">Squires, Chandler, Magliacane, Sara, Greenewald, Kristjan, Katz, Dmitriy, Kocaoglu, Murat, and Shanmugam, Karthikeyan
          </div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>In Advances in Neural Information Processing Systems</em> 17–23 jul 2020
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a href="https://proceedings.neurips.cc/paper/2020/file/f57bd0a58e953e5c43cd4a4e5af46138-Paper.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">HTML</a>
            <a href="https://proceedings.neurips.cc/paper/2020/file/f57bd0a58e953e5c43cd4a4e5af46138-Paper.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a>
            <a href="https://github.com/csquires/dct-policy" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Code</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>A growing body of work has begun to study intervention design for efficient
structure learning of causal directed acyclic graphs (DAGs). A typical setting is
a causally sufficient setting, i.e. a system with no latent confounders, selection
bias, or feedback, when the essential graph of the observational equivalence class
(EC) is given as an input and interventions are assumed to be noiseless. Most
existing works focus on worst-case or average-case lower bounds for the number
of interventions required to orient a DAG. These worst-case lower bounds only
establish that the largest clique in the essential graph could make it difficult to
learn the true DAG. In this work, we develop a universal lower bound for singlenode interventions that establishes that the largest clique is always a fundamental
impediment to structure learning. Specifically, we present a decomposition of a
DAG into independently orientable components through directed clique trees and
use it to prove that the number of single-node interventions necessary to orient any
DAG in an EC is at least the sum of half the size of the largest cliques in each chain
component of the essential graph. Moreover, we present a two-phase intervention
design algorithm that, under certain conditions on the chordal skeleton, matches
the optimal number of interventions up to a multiplicative logarithmic factor in the
number of maximal cliques. We show via synthetic experiments that our algorithm
can scale to much larger graphs than most of the related work and achieves better
worst-case performance than other scalable approaches.</p>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge">NeurIPS</abbr></div>

        <!-- Entry bib key -->
        <div id="magliacane2018domain" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">Domain Adaptation by Using Causal Inference to Predict Invariant Conditional Distributions</div>
          <!-- Author -->
          <div class="author">Magliacane, Sara, Ommen, Thijs, Claassen, Tom, Bongers, Stephan, Versteeg, Philip, and Mooij, Joris M
          </div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>In Advances in Neural Information Processing Systems</em> 17–23 jul 2018
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a href="https://proceedings.neurips.cc/paper/2018/file/39e98420b5e98bfbdc8a619bef7b8f61-Paper.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">HTML</a>
            <a href="https://proceedings.neurips.cc/paper/2018/file/39e98420b5e98bfbdc8a619bef7b8f61-Paper.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a>
            <a href="https://github.com/caus-am/dom_adapt" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Code</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>An important goal common to domain adaptation and causal inference is to make accurate predictions when the distributions for the source (or training) domain(s) and target (or test) domain(s) differ. In many cases, these different distributions can be modeled as different contexts of a single underlying system, in which each distribution corresponds to a different perturbation of the system, or in causal terms, an intervention. We focus on a class of such causal domain adaptation problems, where data for one or more source domains are given, and the task is to predict the distribution of a certain target variable from measurements of other variables in one or more target domains. We propose an approach for solving these problems that exploits causal inference and does not rely on prior knowledge of the causal graph, the type of interventions or the intervention targets. We demonstrate our approach by evaluating a possible implementation on simulated and real world data.</p>
          </div>
        </div>
      </div>
</li>
</ol>
</div>
 


</div>

  </article>

</div>

    </div>

    <!-- Footer -->    
    <footer class="fixed-bottom">
      <div class="container mt-0">
        © Copyright 2026 AMLab  | Amsterdam Machine Learning Lab. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="noopener noreferrer">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" target="_blank" rel="noopener noreferrer">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="noopener noreferrer">GitHub Pages</a>.

      </div>
    </footer>

    <!-- JavaScripts -->
    <!-- jQuery -->
  <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script>

    <!-- Bootsrap & MDB scripts -->
  <script src="https://cdn.jsdelivr.net/npm/@popperjs/core@2.11.2/dist/umd/popper.min.js" integrity="sha256-l/1pMF/+J4TThfgARS6KwWrk/egwuVvhRzfLAMQ6Ds4=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.min.js" integrity="sha256-SyTu6CwrfOhaznYZPoolVw2rxoY7lKYKQvqbtqN93HI=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script>

    <!-- Masonry & imagesLoaded -->
  <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script>
  <script defer src="/assets/js/masonry.js" type="text/javascript"></script>
    
  <!-- Medium Zoom JS -->
  <script src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.6/dist/medium-zoom.min.js" integrity="sha256-EdPgYcPk/IIrw7FYeuJQexva49pVRZNmt3LculEr7zM=" crossorigin="anonymous"></script>
  <script src="/assets/js/zoom.js"></script><!-- Load Common JS -->
  <script src="/assets/js/common.js"></script>

    <!-- MathJax -->
  <script type="text/javascript">
    window.MathJax = {
      tex: {
        tags: 'ams'
      }
    };
  </script>
  <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script>
  <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>

    
  </body>
</html>

