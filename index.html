<!DOCTYPE html>
<html lang="en">

  <!-- Head -->
  <head>    <!-- Metadata, OpenGraph and Schema.org -->
    

    <!-- Standard metadata -->
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <title>AMLab  | Amsterdam Machine Learning Lab</title>
    <meta name="author" content="AMLab  | Amsterdam Machine Learning Lab" />
    <meta name="description" content="Amsterdam Machine Learning Lab, Informatics Institute, University of Amsterdam 
" />
    <meta name="keywords" content="machine learning research" />


    <!-- Bootstrap & MDB -->
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous" />

    <!-- Fonts & Icons -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous">
    <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons">

    <!-- Code Syntax Highlighting -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="none" id="highlight_theme_light" />

    <!-- Styles -->
    
    <link rel="shortcut icon" href="/assets/img/AMLab-logo.svg"/>
    
    <link rel="stylesheet" href="/assets/css/main.css">
    <link rel="canonical" href="https://amlab-amsterdam.github.io/">
    
    <!-- Dark Mode -->
    

  </head>

  <!-- Body -->
  <body class="fixed-top-nav ">

    <!-- Header -->
    <header>

      <!-- Nav Bar -->
      <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top">
        <div class="container">
          <a class="navbar-brand title font-weight-lighter" href="https://AMLab-Amsterdam.github.io/"><span class="font-weight-bold">AMLab</span>   | Amsterdam Machine Learning Lab</a>
          <!-- Navbar Toggle -->
          <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
            <span class="sr-only">Toggle navigation</span>
            <span class="icon-bar top-bar"></span>
            <span class="icon-bar middle-bar"></span>
            <span class="icon-bar bottom-bar"></span>
          </button>

          <div class="collapse navbar-collapse text-right" id="navbarNav">
            <ul class="navbar-nav ml-auto flex-nowrap">

              <!-- About -->
              <!-- <li class="nav-item ">
                <a class="nav-link" href="/">about</a>
              </li> -->
              
              <!-- Blog -->
              <li class="nav-item ">
                <a class="nav-link" href="/blog/">Blog</a>
              </li>

              <!-- Other pages -->
              <li class="nav-item ">
                <a class="nav-link" href="/contact/">Contact</a>
              </li>
              <li class="nav-item ">
                <a class="nav-link" href="/joining/">Joining</a>
              </li>
              <li class="nav-item ">
                <a class="nav-link" href="/people/">People</a>
              </li>
              <li class="nav-item ">
                <a class="nav-link" href="/publications/">Publications</a>
              </li>
            </ul>
          </div>
        </div>
      </nav>
    </header>

    <!-- Content -->
    <div class="container mt-5">
      <!-- about.html -->
      <div class="post">
        <header class="post-header">
          <h1 class="post-title">
           <span class="font-weight-bold">AMLab</span>  | Amsterdam Machine Learning Lab
          </h1>
          <p class="desc"></p>
        </header>

        <article>
          <div class="profile float-right">
<figure>

  <picture>
<!--     <source media="(max-width: 480px)" srcset="/assets/img/AMLab-logo.svg-480.webp" />
    <source media="(max-width: 800px)" srcset="/assets/img/AMLab-logo.svg-800.webp" />
    <source media="(max-width: 1400px)" srcset="/assets/img/AMLab-logo.svg-1400.webp" />
    -->
    <!-- Fallback to the original file -->
    <img class="img-fluid z-dept-1 rounded" src="/assets/img/AMLab-logo.svg" alt="AMLab-logo.svg">

  </picture>

</figure>

          </div>

          <div class="clearfix">
            <p>The Amsterdam Machine Learning Lab (AMLab) conducts research in machine learning, artificial intelligence, and its applications to large scale data domains in science and industry. This includes the development of deep generative models, methods for approximate inference, probabilistic programming, Bayesian deep learning, causal inference, reinforcement learning, graph neural networks, and geometric deep learning.</p>

<p>AMLab comprises 7 faculty. <a href="https://jwvdm.github.io/" target="_blank" rel="noopener noreferrer">Jan-Willem van de Meent</a>, who serves as director, <a href="https://staff.fnwi.uva.nl/m.welling/" target="_blank" rel="noopener noreferrer">Max Welling</a>, <a href="https://staff.fnwi.uva.nl/h.c.vanhoof/homepage/" target="_blank" rel="noopener noreferrer">Herke van Hoof</a>, <a href="">Patrick Forré</a>, <a href="https://erikbekkers.bitbucket.io/" target="_blank" rel="noopener noreferrer">Erik Bekkers</a>, <a href="https://naesseth.github.io/" target="_blank" rel="noopener noreferrer">Christian Naesseth</a>, and <a href="http://amlab.science.uva.nl/people/SaraMagliacane" target="_blank" rel="noopener noreferrer">Sara Magliacane</a>. The lab participates in public-private partnerships with industry through the <a href="https://ivi.fnwi.uva.nl/quva/" target="_blank" rel="noopener noreferrer">QUvA Lab</a> (with Qualcomm) and the <a href="https://ivi.fnwi.uva.nl/uvaboschdeltalab/" target="_blank" rel="noopener noreferrer">Delta Lab</a> (with Bosch). The lab also engages in cross-disciplinary collaborations through the <a href="https://ai4science-amsterdam.github.io/" target="_blank" rel="noopener noreferrer">AI4Science Lab</a>.</p>

          </div>

          <!-- News -->          
          <div class="news">
            <h2>News</h2>
            <div class="table-responsive">
              <table class="table table-sm table-borderless"> 
                <tr>
                  <th scope="row">Nov 7, 2024</th>
                  <td>
                    The AMLAB has an open postdoc position on support human decision making using reinforcement learning. 
You will be working with <a href="people/HerkeVanHoof">Herke van Hoof</a> and <a href="https://www.fransoliehoek.net/wp/" target="_blank" rel="noopener noreferrer">Frans Oliehoek</a>.
Full details and instructions to apply can be found in the <a href="https://vacatures.uva.nl/UvA/job/Postdoc-on-Supporting-Human-Decision-Making-with-Reinforcement-Learning/806531602/" target="_blank" rel="noopener noreferrer">official vacancy</a>.

The position is part of the <a href="https://twitter.com/AI4REALNET" target="_blank" rel="noopener noreferrer">AI4REALNET</a> project that receives funding from the European Union’s Horizon Europe programme, and the <a href="https://www.hybrid-intelligence-centre.nl" target="_blank" rel="noopener noreferrer">Hybrid Intelligence project</a> that receives funding from the NWO.

 
                  </td>
                </tr> 
                <tr>
                  <th scope="row">May 7, 2024</th>
                  <td>
                    Congratulations to <a href="http://www.dpkingma.com/" target="_blank" rel="noopener noreferrer">Durk Kingma</a> and <a href="https://amlab.science.uva.nl/people/MaxWelling/" target="_blank" rel="noopener noreferrer">Max Welling</a> on receiving the inaugural <a href="https://blog.iclr.cc/2024/05/07/iclr-2024-test-of-time-award/" target="_blank" rel="noopener noreferrer">test-of-time award at ICLR 2024</a>!
 
                  </td>
                </tr> 
                <tr>
                  <th scope="row">Apr 26, 2024</th>
                  <td>
                    The BeNeRL workshop on reinforcement learning will take place June 10th in Amsterdam! The programme includes 
keynotes by Frans Oliehoek, Roxana Radulescu, Thomas Moerland, Thiago Dias Simao, and Yailen Martinez Jimenez. The workshop is free to attend but registration is required. 
More information and registration via the <a href="https://benerl.org/workshop/2024-amsterdam" target="_blank" rel="noopener noreferrer">workshop website</a>. The workshop is supported by <a href="https://ivi.fnwi.uva.nl/ellis/" target="_blank" rel="noopener noreferrer">Ellis Amsterdam</a> and <a href="http://nwo.nl" target="_blank" rel="noopener noreferrer">NWO</a>.

 
                  </td>
                </tr> 
                <tr>
                  <th scope="row">Jan 26, 2024</th>
                  <td>
                    <a href="people/SaraMagliacane">Sara Magliacane</a> and <a href="people/HerkeVanHoof">Herke van Hoof</a> have two open PhD positions on machine learning in the fintech domain (in collaboration with <a href="https://www.adyen.com" target="_blank" rel="noopener noreferrer">Adyen</a>). One student will work on causal machine learning, and the second student will work on reinforcement learning. Deadline for applications is March  11th. For all details and how to apply, please see the <a href="https://vacatures.uva.nl/UvA/job/2-PhD-positions-on-causal-machine-learning-and-reinforcement-learning-for-FinTech/785937402/" target="_blank" rel="noopener noreferrer">official vacancy</a>.

 
                  </td>
                </tr> 
                <tr>
                  <th scope="row">Jan 4, 2024</th>
                  <td>
                    We currently have two postdoc openings at AMLab, both with deadline of Februari 4th:

<ol>
  <li>
    <a href="people/ChristianNaesseth">Christian Naesseth</a> is hiring for a postdoc position focusing topics relating to generative AI, AI4Science, or uncertainty quantification. This position is part of the <a href="https://ivi.fnwi.uva.nl/uvaboschdeltalab/" target="_blank" rel="noopener noreferrer">UvA Bosch Delta Lab</a>. You can apply <a href="https://vacatures.uva.nl/UvA/job/Postdoctoral-Researcher-in-Machine-Learning/784737702/" target="_blank" rel="noopener noreferrer">here</a>.
  </li>
  <li>
    <a href="people/JanWillemvandeMeent">Jan-Willem van de Meent</a> is hiring for a postdoc position in AI methods for sustainability, including Bayesian optimization and experiment design, data-efficient surrogate modeling, probabilistic programming, and simulation-based inference. This position is part of the <a href="https://elias-ai.eu/" target="_blank" rel="noopener noreferrer">ELiAS program</a>. You can apply <a href="https://vacatures.uva.nl/UvA/job/Postdoctoral-Researcher-in-AI-for-Sustainability/785625202/" target="_blank" rel="noopener noreferrer">here</a>.
  </li>
</ol>
 
                  </td>
                </tr> 
              </table>
            </div> 
          </div>


          <!-- Selected papers -->
          <div class="publications">
            <h2>Recent Publications</h2>
            <ol class="bibliography">
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge">ICLR</abbr></div>

        <!-- Entry bib key -->
        <div id="tailor2025approxfcp" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">Approximating Full Conformal Prediction for Neural Network Regression with Gauss-Newton Influence</div>
          <!-- Author -->
          <div class="author">Tailor, Dharmesh, Correia, Alvaro, Nalisnick, Eric, and Louizos, Christos
          </div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>In 13th International Conference on Learning Representations (to appear)</em> Apr 2025
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a href="https://openreview.net/forum?id=vcX0k4rGTt" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">HTML</a>
          </div>

          
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge">CIKM</abbr></div>

        <!-- Entry bib key -->
        <div id="mansoury2024mitigating" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">Mitigating Exposure Bias in Online Learning to Rank Recommendation: A Novel Reward Model for Cascading Bandits</div>
          <!-- Author -->
          <div class="author">Mansoury, Masoud, Mobasher, Bamshad, and Hoof, Herke
          </div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>In ACM International Conference on Information and Knowledge Management</em> Apr 2024
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a href="http://arxiv.org/abs/https://arxiv.org/abs/2408.04332" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">arXiv</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="https://dl.acm.org/doi/10.1145/3627673.3679763" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">HTML</a>
          </div>

          <!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">mansoury2024mitigating</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Mitigating Exposure Bias in Online Learning to Rank Recommendation: A Novel Reward Model for Cascading Bandits}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Mansoury, Masoud and Mobasher, Bamshad and van Hoof, Herke}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">date</span> <span class="p">=</span> <span class="s">{2024-10-21}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{ACM International Conference on Information and Knowledge Management}</span><span class="p">,</span>
  <span class="na">abbr</span> <span class="p">=</span> <span class="s">{CIKM}</span><span class="p">,</span>
  <span class="na">html</span> <span class="p">=</span> <span class="s">{https://dl.acm.org/doi/10.1145/3627673.3679763}</span><span class="p">,</span>
  <span class="na">bibtex_show</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">arxiv</span> <span class="p">=</span> <span class="s">{https://arxiv.org/abs/2408.04332}</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge">SIGIR</abbr></div>

        <!-- Entry bib key -->
        <div id="huang2024going" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">Going Beyond Popularity and Positivity Bias: Correcting for Multifactorial Bias in Recommender Systems</div>
          <!-- Author -->
          <div class="author">Huang, Jin, Oosterhuis, Harrie, Mansoury, Masoud, Hoof, Herke, and Rijke, Maarten
          </div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>In International ACM SIGIR Conference on Research and Development in Information Retrieval</em> Apr 2024
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a href="http://arxiv.org/abs/https://arxiv.org/abs/2404.18640" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">arXiv</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="https://dl.acm.org/doi/10.1145/3626772.3657749" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">HTML</a>
          </div>

          <!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">huang2024going</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Going Beyond Popularity and Positivity Bias: Correcting for Multifactorial Bias in Recommender Systems}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Huang, Jin and Oosterhuis, Harrie and Mansoury, Masoud and van Hoof, Herke and de Rijke, Maarten}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://arxiv.org/abs/2404.18640}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">date</span> <span class="p">=</span> <span class="s">{2024-07-14}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{International ACM SIGIR Conference on Research and Development in Information Retrieval}</span><span class="p">,</span>
  <span class="na">abbr</span> <span class="p">=</span> <span class="s">{SIGIR}</span><span class="p">,</span>
  <span class="na">html</span> <span class="p">=</span> <span class="s">{https://dl.acm.org/doi/10.1145/3626772.3657749}</span><span class="p">,</span>
  <span class="na">bibtex_show</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">arxiv</span> <span class="p">=</span> <span class="s">{https://arxiv.org/abs/2404.18640}</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge">NeurIPS</abbr></div>

        <!-- Entry bib key -->
        <div id="jazbec2024fastyetsafe" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">Fast yet Safe: Early-Exiting with Risk Control</div>
          <!-- Author -->
          <div class="author">Jazbec*, Metod, Timans*, Alexander, Veljković, Tin Hadži, Sakmann, Kaspar, Zhang, Dan, Naesseth, Christian A, and Nalisnick, Eric
          </div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>Advances in Neural Information Processing Systems</em> Dec 2024
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a href="http://arxiv.org/abs/2405.20915" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">arXiv</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
          </div>

          <!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">jazbec2024fastyetsafe</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Fast yet Safe: Early-Exiting with Risk Control}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Jazbec*, Metod and Timans*, Alexander and Veljkovi{\'c}, Tin Had{\v{z}}i and Sakmann, Kaspar and Zhang, Dan and Naesseth, Christian A and Nalisnick, Eric}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Advances in Neural Information Processing Systems}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{37}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">dec</span><span class="p">,</span>
  <span class="na">abbr</span> <span class="p">=</span> <span class="s">{NeurIPS}</span><span class="p">,</span>
  <span class="na">annotation</span> <span class="p">=</span> <span class="s">{* Equal contribution}</span><span class="p">,</span>
  <span class="na">arxiv</span> <span class="p">=</span> <span class="s">{2405.20915}</span><span class="p">,</span>
  <span class="na">bibtex_show</span> <span class="p">=</span> <span class="s">{true}</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge">NeurIPS</abbr></div>

        <!-- Entry bib key -->
        <div id="bartosh2024neural" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">Neural Flow Diffusion Models: Learnable Forward Process for Improved Diffusion Modelling</div>
          <!-- Author -->
          <div class="author">Bartosh, Grigory, Vetrov, Dmitry, and Naesseth, Christian A
          </div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>Advances in Neural Information Processing Systems</em> Dec 2024
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a href="http://arxiv.org/abs/2404.12940" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">arXiv</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
          </div>

          <!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">bartosh2024neural</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Neural Flow Diffusion Models: Learnable Forward Process for Improved Diffusion Modelling}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Bartosh, Grigory and Vetrov, Dmitry and Naesseth, Christian A}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Advances in Neural Information Processing Systems}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{37}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">dec</span><span class="p">,</span>
  <span class="na">abbr</span> <span class="p">=</span> <span class="s">{NeurIPS}</span><span class="p">,</span>
  <span class="na">arxiv</span> <span class="p">=</span> <span class="s">{2404.12940}</span><span class="p">,</span>
  <span class="na">bibtex_show</span> <span class="p">=</span> <span class="s">{true}</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge">NeurIPS</abbr></div>

        <!-- Entry bib key -->
        <div id="eijkelboom2024variational" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">Variational Flow Matching for Graph Generation</div>
          <!-- Author -->
          <div class="author">Eijkelboom*, Floor, Bartosh*, Grigory, Naesseth, Christian Andersson, Welling, Max, and Meent, Jan-Willem
          </div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>Advances in Neural Information Processing Systems</em> Dec 2024
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a href="http://arxiv.org/abs/2406.04843" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">arXiv</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
          </div>

          <!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">eijkelboom2024variational</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Variational Flow Matching for Graph Generation}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Eijkelboom*, Floor and Bartosh*, Grigory and Naesseth, Christian Andersson and Welling, Max and van de Meent, Jan-Willem}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Advances in Neural Information Processing Systems}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{37}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">dec</span><span class="p">,</span>
  <span class="na">abbr</span> <span class="p">=</span> <span class="s">{NeurIPS}</span><span class="p">,</span>
  <span class="na">annotation</span> <span class="p">=</span> <span class="s">{* Equal contribution}</span><span class="p">,</span>
  <span class="na">arxiv</span> <span class="p">=</span> <span class="s">{2406.04843}</span><span class="p">,</span>
  <span class="na">bibtex_show</span> <span class="p">=</span> <span class="s">{true}</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge">NeurIPS</abbr></div>

        <!-- Entry bib key -->
        <div id="cornet2024equivariant" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">Equivariant Neural Diffusion for Molecule Generation</div>
          <!-- Author -->
          <div class="author">Cornet, François RJ, Bartosh, Grigory, Schmidt, Mikkel N, and Naesseth, Christian A
          </div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>Advances in Neural Information Processing Systems</em> Dec 2024
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="https://openreview.net/forum?id=3iih8PGAH7" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">HTML</a>
          </div>

          <!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">cornet2024equivariant</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Equivariant Neural Diffusion for Molecule Generation}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Cornet, Fran{\c{c}}ois RJ and Bartosh, Grigory and Schmidt, Mikkel N and Naesseth, Christian A}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Advances in Neural Information Processing Systems}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{37}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">dec</span><span class="p">,</span>
  <span class="na">abbr</span> <span class="p">=</span> <span class="s">{NeurIPS}</span><span class="p">,</span>
  <span class="na">html</span> <span class="p">=</span> <span class="s">{https://openreview.net/forum?id=3iih8PGAH7}</span><span class="p">,</span>
  <span class="na">bibtex_show</span> <span class="p">=</span> <span class="s">{true}</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge">ICML</abbr></div>

        <!-- Entry bib key -->
        <div id="bartosh2023neural" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">Neural Diffusion Models</div>
          <!-- Author -->
          <div class="author">Bartosh, Grigory, Vetrov, Dmitry, and Naesseth, Christian A
          </div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>The 41st International Conference on Machine Learning (ICML)</em> Jul 2024
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a href="http://arxiv.org/abs/2310.08337" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">arXiv</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
          </div>

          <!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">bartosh2023neural</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Neural Diffusion Models}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Bartosh, Grigory and Vetrov, Dmitry and Naesseth, Christian A}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{The 41st International Conference on Machine Learning (ICML)}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">jul</span><span class="p">,</span>
  <span class="na">abbr</span> <span class="p">=</span> <span class="s">{ICML}</span><span class="p">,</span>
  <span class="na">arxiv</span> <span class="p">=</span> <span class="s">{2310.08337}</span><span class="p">,</span>
  <span class="na">bibtex_show</span> <span class="p">=</span> <span class="s">{true}</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge">UAI</abbr></div>

        <!-- Entry bib key -->
        <div id="jazbec2024nestedeenns" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">Early-Exit Neural Networks with Nested Prediction Sets</div>
          <!-- Author -->
          <div class="author">Jazbec, Metod, Forré, Patrick, Mandt, Stephan, Zhang, Dan, and Nalisnick, Eric
          </div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>The 40th Conference on Uncertainty in Artificial Intelligence</em> Aug 2024
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a href="http://arxiv.org/abs/2311.05931" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">arXiv</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
          </div>

          <!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">jazbec2024nestedeenns</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Early-Exit Neural Networks with Nested Prediction Sets}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Jazbec, Metod and Forr{\'e}, Patrick and Mandt, Stephan and Zhang, Dan and Nalisnick, Eric}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{The 40th Conference on Uncertainty in Artificial Intelligence}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">aug</span><span class="p">,</span>
  <span class="na">abbr</span> <span class="p">=</span> <span class="s">{UAI}</span><span class="p">,</span>
  <span class="na">arxiv</span> <span class="p">=</span> <span class="s">{2311.05931}</span><span class="p">,</span>
  <span class="na">bibtex_show</span> <span class="p">=</span> <span class="s">{true}</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge">ICAPS</abbr></div>

        <!-- Entry bib key -->
        <div id="kuric2024planning" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">Planning with a Learned Policy Basis to Optimally Solve Complex Tasks</div>
          <!-- Author -->
          <div class="author">Kuric, D., Infante, G., Gómez, V., Jonsson, A., and Hoof, H.
          </div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>In International Conference on Automated Planning and Scheduling</em> Aug 2024
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a href="https://openreview.net/forum?id=6N1uCtBhcL" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">HTML</a>
            <a href="https://openreview.net/pdf?id=6N1uCtBhcL" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a>
          </div>

          
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge">AAMAS</abbr></div>

        <!-- Entry bib key -->
        <div id="loftin2024uncoupled" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">Uncoupled Learning of Differential Stackelberg Equilibria with Commitments</div>
          <!-- Author -->
          <div class="author">Loftin, Robert, Çelikok, Mustafa Mert, Hoof, Herke, Kaski, Samuel, and Oliehoek, Frans
          </div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>In Artificial Agents and Multi-Agent Systems (AAMAS)</em> Aug 2024
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a href="https://arxiv.org/abs/2302.03438" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">HTML</a>
            <a href="https://arxiv.org/pdf/2302.03438" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a>
          </div>

          
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge">AISTATS</abbr></div>

        <!-- Entry bib key -->
        <div id="tailor2024l2dmeta" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">Learning to Defer to a Population: A Meta-Learning Approach</div>
          <!-- Author -->
          <div class="author">Tailor, Dharmesh, Patra, Aditya, Verma, Rajeev, Manggala, Putra, and Nalisnick, Eric
          </div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>In 27th International Conference on Artificial Intelligence and Statistics</em> May 2024
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a href="https://proceedings.mlr.press/v238/tailor24a.html" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">HTML</a>
          </div>

          
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge">ICLR</abbr></div>

        <!-- Entry bib key -->
        <div id="kunze2024entropy" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">Entropy Coding of Unordered Data Structures</div>
          <!-- Author -->
          <div class="author">Kunze, Julius, Severo, Daniel, Zani, Giulio, van de Meent, Jan-Willem, and Townsend, James
          </div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>In International Conference on Learning Representations (ICLR)</em> May 2024
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
          </div>

          
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge">ECML</abbr></div>

        <!-- Entry bib key -->
        <div id="learning2023woehlke" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">Learning Hierarchical Planning-Based Policies from Offline Data</div>
          <!-- Author -->
          <div class="author">Woehlke, J., Schmitt, F., and Hoof, H.
          </div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>In Machine Learning and Knowledge Discovery in Databases: Research Track (ECML PKDD)</em> May 2023
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a href="https://link.springer.com/chapter/10.1007/978-3-031-43421-1_29" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">HTML</a>
          </div>

          
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge">EMNLP</abbr></div>

        <!-- Entry bib key -->
        <div id="mcinerney2023chill" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">CHiLL: Zero-shot Custom Interpretable Feature Extraction from Clinical Notes with Large Language Models</div>
          <!-- Author -->
          <div class="author">McInerney, Denis Jered, Young, Geoffrey, Meent, Jan-Willem, and Wallace, Byron
          </div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>In The 2023 Conference on Empirical Methods in Natural Language Processing (to appear)</em> May 2023
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
          </div>

          
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge">EMNLP</abbr></div>

        <!-- Entry bib key -->
        <div id="naszadimanggala2022aligning" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">Aligning Predictive Uncertainty with Clarification Questions in Grounded Dialog</div>
          <!-- Author -->
          <div class="author">Naszadi, Kata, Manggala, Putra, and Monz, Christof
          </div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>In The 2023 Conference on Empirical Methods in Natural Language Processing (to appear)</em> Dec 2023
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
          </div>

          
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge">NeurIPS</abbr></div>

        <!-- Entry bib key -->
        <div id="zhdanov2022implicit" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">Implicit Neural Convolutional Kernels for Steerable CNNs</div>
          <!-- Author -->
          <div class="author">Zhdanov, Maksim, Hoffmann, Nico, and Cesa, Gabriele
          </div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>In Thirty-seventh Conference on Neural Information Processing Systems (to appear)</em> Dec 2023
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
          </div>

          
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge">NeurIPS</abbr></div>

        <!-- Entry bib key -->
        <div id="song2023flow" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">Flow Factorzied Representation Learning</div>
          <!-- Author -->
          <div class="author">Song, Yue, Keller, T Anderson, Sebe, Nicu, and Welling, Max
          </div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>In Thirty-seventh Conference on Neural Information Processing Systems (to appear)</em> Dec 2023
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
          </div>

          
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge">NeurIPS</abbr></div>

        <!-- Entry bib key -->
        <div id="slowe2023rotating" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">Rotating Features for Object Discovery</div>
          <!-- Author -->
          <div class="author">
          </div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>In Thirty-seventh Conference on Neural Information Processing Systems (to appear)</em> Dec 2023
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
          </div>

          
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge">NeurIPS</abbr></div>

        <!-- Entry bib key -->
        <div id="kofinas2023latent" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">Latent Field Discovery in Interacting Dynamical Systems with Neural Fields</div>
          <!-- Author -->
          <div class="author">Kofinas, Miltiadis, Bekkers, Erik J, Nagaraja, Naveen Shankar, and Gavves, Efstratios
          </div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>In Thirty-seventh Conference on Neural Information Processing Systems (to appear)</em> Dec 2023
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
          </div>

          
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge">NeurIPS</abbr></div>

        <!-- Entry bib key -->
        <div id="jazbec2023towards" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">Towards Anytime Classification in Early-Exit Architectures by Enforcing Conditional Monotonicity</div>
          <!-- Author -->
          <div class="author">Jazbec, Metod, Allingham, James Urquhart, Zhang, Dan, and Nalisnick, Eric
          </div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>In Thirty-seventh Conference on Neural Information Processing Systems (to appear)</em> Dec 2023
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
          </div>

          
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge">NeurIPS</abbr></div>

        <!-- Entry bib key -->
        <div id="feng2023learning" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">Learning Dynamic Attribute-factored World Models for Efficient Multi-object Reinforcement Learning</div>
          <!-- Author -->
          <div class="author">Feng, Fan, and Magliacane, Sara
          </div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>In Thirty-seventh Conference on Neural Information Processing Systems (to appear)</em> Dec 2023
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
          </div>

          
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge">NeurIPS</abbr></div>

        <!-- Entry bib key -->
        <div id="auzina2023invariant" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">Invariant Neural Ordinary Differential Equations</div>
          <!-- Author -->
          <div class="author">Auzina, Ilze Amanda, Yıldız, Çağatay, Magliacane, Sara, Bethge, Matthias, and Gavves, Efstratios
          </div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>In Thirty-seventh Conference on Neural Information Processing Systems (to appear)</em> Dec 2023
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
          </div>

          
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge">NeurIPS</abbr></div>

        <!-- Entry bib key -->
        <div id="ruhe2023clifford" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">Clifford group equivariant neural networks</div>
          <!-- Author -->
          <div class="author">Ruhe, David, Brandstetter, Johannes, and Forré, Patrick
          </div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>In Thirty-seventh Conference on Neural Information Processing Systems (to appear)</em> Dec 2023
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
          </div>

          
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge">NeurIPS</abbr></div>

        <!-- Entry bib key -->
        <div id="lippert2023deep" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">Deep Gaussian Markov Random Fields for Graph-Structured Dynamical Systems</div>
          <!-- Author -->
          <div class="author">Lippert, Fiona, Kranstauber, Bart, Loon, E Emiel, and Forré, Patrick
          </div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>In Thirty-seventh Conference on Neural Information Processing Systems (to appear)</em> Dec 2023
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
          </div>

          
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge">NeurIPS</abbr></div>

        <!-- Entry bib key -->
        <div id="wu2023practical" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">Practical and Asymptotically Exact Conditional Sampling in Diffusion Models</div>
          <!-- Author -->
          <div class="author">Wu, Luhuan, Trippe, Brian L, Naesseth, Christian A, Blei, David M, and Cunningham, John P
          </div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>In Thirty-seventh Conference on Neural Information Processing Systems (to appear)</em> Dec 2023
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
          </div>

          
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge">NeurIPS</abbr></div>

        <!-- Entry bib key -->
        <div id="esmaeili2023topological" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">Topological Obstructions and How to Avoid Them</div>
          <!-- Author -->
          <div class="author">Esmaeili, Babak, Walters, Robin, Zimmermann, Heiko, and van de Meent, Jan-Willem
          </div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>In Thirty-seventh Conference on Neural Information Processing Systems (to appear)</em> Dec 2023
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a href="https://openreview.net/forum?id=1tviRBNxI9" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">HTML</a>
          </div>

          
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge">NeurIPS</abbr></div>

        <!-- Entry bib key -->
        <div id="nickl2023memoryperturbation" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">The Memory-Perturbation Equation: Understanding Model’s Sensitivity to Data</div>
          <!-- Author -->
          <div class="author">Nickl, Peter, Xu, Lu*, Tailor, Dharmesh*, Möllenhoff, Thomas, and Khan, Mohammad Emtiyaz
          </div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>In Thirty-seventh Conference on Neural Information Processing Systems</em> Dec 2023
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a href="https://openreview.net/forum?id=dqS1GuoG2V" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">HTML</a>
          </div>

          
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge">CoRL</abbr></div>

        <!-- Entry bib key -->
        <div id="biza2023oneshot" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">One-shot Imitation Learning via Interaction Warping</div>
          <!-- Author -->
          <div class="author">Biza, Ondrej, Thompson, Skye, Pagidi, Kishore Reddy, Kumar, Abhinav, Pol, Elise, Walters, Robin, Kipf, Thomas, Meent, Jan-Willem, Wong, Lawson L.S., and Platt, Robert
          </div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>In 7th Annual Conference on Robot Learning</em> Nov 2023
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a href="https://openreview.net/forum?id=RaNAaxZfKi8" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">HTML</a>
          </div>

          
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge">UAI</abbr></div>

        <!-- Entry bib key -->
        <div id="tailor2023exploiting" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">Exploiting Inferential Structure in Neural Processes</div>
          <!-- Author -->
          <div class="author">Tailor, Dharmesh, Khan, Mohammad Emtiyaz, and Nalisnick, Eric
          </div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>In The 39th Conference on Uncertainty in Artificial Intelligence</em> Aug 2023
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a href="https://proceedings.mlr.press/v216/tailor23a.html" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">HTML</a>
          </div>

          
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge">ACT</abbr></div>

        <!-- Entry bib key -->
        <div id="sennesh2023string" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">String Diagrams with Factorized Densities</div>
          <!-- Author -->
          <div class="author">Sennesh, Eli, and van de Meent, Jan-Willem
          </div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>In Applied Category Theory</em> Jul 2023
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a href="https://arxiv.org/abs/2305.02506" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">HTML</a>
            <a href="https://arxiv.org/pdf/2305.02506.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>A growing body of research on probabilistic programs and causal models has highlighted the need to reason compositionally about model classes that extend directed graphical models. Both probabilistic programs and causal models define a joint probability density over a set of random variables, and exhibit sparse structure that can be used to reason about causation and conditional independence. This work builds on recent work on Markov categories of probabilistic mappings to define a category whose morphisms combine a joint density, factorized over each sample space, with a deterministic mapping from samples to return values. This is a step towards closing the gap between recent category-theoretic descriptions of probability measures, and the operational definitions of factorized densities that are commonly employed in probabilistic programming and causal inference.</p>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge">TMLR</abbr></div>

        <!-- Entry bib key -->
        <div id="kuric2023reusable" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">Reusable Options through Gradient-based Meta Learning</div>
          <!-- Author -->
          <div class="author">Kuric, David, and Hoof, Herke
          </div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>Transactions on Machine Learning Research</em> Mar 2023
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a href="https://openreview.net/forum?id=qdDmxzGuzu" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">HTML</a>
            <a href="https://openreview.net/pdf?id=qdDmxzGuzu" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a>
            <a href="https://github.com/Kuroo/FAMP" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Code</a>
            <a href="https://youtu.be/Dp5a20y9ohw" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Video</a>
          </div>

          
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge">TMLR</abbr></div>

        <!-- Entry bib key -->
        <div id="zimmermann2023variational" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">A Variational Perspective on Generative Flow Networks</div>
          <!-- Author -->
          <div class="author">Zimmermann, Heiko, Lindsten, Fredrik, Meent, Jan-Willem, and Naesseth, Christian A
          </div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>Transactions on Machine Learning Research</em> Apr 2023
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a href="https://openreview.net/forum?id=AZ4GobeSLq" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">HTML</a>
            <a href="https://openreview.net/pdf?id=AZ4GobeSLq" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a>
            <a href="https://github.com/zmheiko/variational-perspective-on-gflownets" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Code</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Generative flow networks (GFNs) are a class of probabilistic models for sequential sampling of composite objects, proportional to a target distribution that is defined in terms of an energy function or a reward. GFNs are typically trained using a flow matching or trajectory balance objective, which matches forward and backward transition models over trajectories. In this work we introduce a variational objective for training GFNs, which is a convex combination of the reverse- and forward KL divergences, and compare it to the trajectory balance objective when sampling from the forward- and backward model, respectively. We show that, in certain settings, variational inference for GFNs is equivalent to minimizing the trajectory balance objective, in the sense that both methods compute the same score-function gradient. This insight suggests that in these settings, control variates, which are commonly used to reduce the variance of score-function gradient estimates, can also be used with the trajectory balance objective. We evaluate our findings and the performance of the proposed variational objective numerically by comparing it to the trajectory balance objective on two synthetic tasks.</p>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge">ICLR</abbr></div>

        <!-- Entry bib key -->
        <div id="wang2023bridge" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">Bridge the Inference Gaps of Neural Processes via Expectation Maximization</div>
          <!-- Author -->
          <div class="author">Wang, Qi, Federici, Marco, and Hoof, Herke
          </div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>In International Conference on Learning Representations</em> Apr 2023
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a href="https://openreview.net/forum?id=A7v2DqLjZdq" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">HTML</a>
          </div>

          
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge">ICLR</abbr></div>

        <!-- Entry bib key -->
        <div id="antoran2023sampling" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">Sampling-Based Inference for Large Linear Models, with Application to Linearised Laplace</div>
          <!-- Author -->
          <div class="author">Antorán, Javier, Padhy, Shreyas, Barbano, Riccardo, Nalisnick, Eric, Janz, David, and Miguel Hernández-Lobato, José
          </div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>In International Conference on Learning Representations</em> Apr 2023
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a href="https://arxiv.org/abs/2210.04994" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">HTML</a>
          </div>

          
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge">AISTATS</abbr></div>

        <!-- Entry bib key -->
        <div id="sharma2023do" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">Do Bayesian Neural Networks Need To Be Fully Stochastic?</div>
          <!-- Author -->
          <div class="author">Sharma, Mrinank, Farquhar, Sebastian, Nalisnick, Eric, and Rainforth, Tom
          </div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>In Proceedings of The 26th International Conference on Artificial Intelligence and Statistics</em> Apr 2023
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a href="https://arxiv.org/abs/2211.06291" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">HTML</a>
          </div>

          
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge">AISTATS</abbr></div>

        <!-- Entry bib key -->
        <div id="verma2023learning" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">Learning to Defer to Multiple Experts: Consistent Surrogate Losses, Confidence Calibration, and Conformal Ensembles</div>
          <!-- Author -->
          <div class="author">Verma, Rajeev, Barrejón, Daniel, and Nalisnick, Eric
          </div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>In Proceedings of The 26th International Conference on Artificial Intelligence and Statistics</em> Apr 2023
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a href="https://arxiv.org/abs/2210.16955" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">HTML</a>
          </div>

          
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge">ECML</abbr></div>

        <!-- Entry bib key -->
        <div id="bakker2023learning" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">Learning objective-specific active learning strategies with Attentive Neural Processes</div>
          <!-- Author -->
          <div class="author">Bakker, Tim, Hoof, Herke, and Welling, Max
          </div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>In Proceedings of the European Conference on Machine Learning</em> Sep 2023
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a href="https://arxiv.org/pdf/2309.05477.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a>
            <a href="https://github.com/Timsey/npal" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Code</a>
          </div>

          
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge">NeurIPS <br> Workshop</abbr></div>

        <!-- Entry bib key -->
        <div id="bakker2023active" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">Active Learning Policies for Solving Inverse Problems</div>
          <!-- Author -->
          <div class="author">Bakker, T., Hehn, T., Orekondy, T., Behboodi, A., and Massoli, F. Valerio
          </div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>In Neural Information Processing Systems Workshop on Adaptive Experimental Design and Active Learning in the Real World</em> Dec 2023
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a href="https://openreview.net/pdf?id=eLIk3m5C79" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a>
          </div>

          
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge">NeurIPS <br> Workshop</abbr></div>

        <!-- Entry bib key -->
        <div id="bakker2023switching" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">Switching policies for solving inverse problems</div>
          <!-- Author -->
          <div class="author">Bakker, T., Massoli, F. Valerio, Hehn, T., Orekondy, T., and Behboodi, A.
          </div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>In Neural Information Processing Systems Workshop on Deep Learning and Inverse Problems</em> Dec 2023
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a href="https://openreview.net/pdf?id=QaIEU0wWj8" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a>
          </div>

          
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge">PLOS Comp Bio</abbr></div>

        <!-- Entry bib key -->
        <div id="smedemark-margulies2022probabilistic" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">Probabilistic Program Inference in Network-Based Epidemiological Simulations</div>
          <!-- Author -->
          <div class="author">Smedemark-Margulies, Niklas, Walters, Robin, Zimmermann, Heiko, Laird, Lucas, Loo, Christian, Kaushik, Neela, Caceres, Rajmonda, and Meent, Jan-Willem
          </div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>PLOS Computational Biology</em> Nov 2022
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a href="https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1010591" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">HTML</a>
            <a href="https://journals.plos.org/ploscompbiol/article/file?id=10.1371/journal.pcbi.1010591&amp;type=printable" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Accurate epidemiological models require parameter estimates that account for mobility patterns and social network structure. We demonstrate the effectiveness of probabilistic programming for parameter inference in these models. We consider an agent-based simulation that represents mobility networks as degree-corrected stochastic block models, whose parameters we estimate from cell phone co-location data. We then use probabilistic program inference methods to approximate the distribution over disease transmission parameters conditioned on reported cases and deaths. Our experiments demonstrate that the resulting models improve the quality of fit in multiple geographies relative to baselines that do not model network topology.</p>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge">IJCNN</abbr></div>

        <!-- Entry bib key -->
        <div id="giri2022logic" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">Logic-based AI for Interpretable Board Game Winner Prediction with Tsetlin Machine</div>
          <!-- Author -->
          <div class="author">Giri, Charul, Granmo, Ole-Christopher, Hoof, Herke, and Blakely, Christian D.
          </div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>In International Joint Conference on Neural Networks</em> Nov 2022
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a href="https://arxiv.org/pdf/2203.04378.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a>
          </div>

          
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge">NeurIPS</abbr></div>

        <!-- Entry bib key -->
        <div id="wang2022learning" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">Learning Expressive Meta-Representations with Mixture of Expert Neural Processes</div>
          <!-- Author -->
          <div class="author">Wang, Qi, and Hoof, Herke
          </div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>In Advances in Neural Information Processing Systems</em> Nov 2022
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Neural processes (NPs) formulate exchangeable stochastic processes and are promising models for meta learning that do not require gradient updates during the testing phase. 
However, most NP variants place a strong emphasis on a global latent variable. 
This weakens the approximation power and restricts the scope of applications using NP variants, especially when data generative processes are complicated.
To resolve these issues, we propose to combine the Mixture of Expert models with Neural Processes to develop more expressive exchangeable stochastic processes, referred to as Mixture of Expert Neural Processes (MoE-NPs). 
Then we apply MoE-NPs to both few-shot supervised learning and meta reinforcement learning tasks. 
Empirical results demonstrate MoE-NPs’ strong generalization capability to unseen tasks in these benchmarks.</p>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge">NeurIPS</abbr></div>

        <!-- Entry bib key -->
        <div id="feng2022factored" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">Factored Adaptation for Non-Stationary Reinforcement Learning</div>
          <!-- Author -->
          <div class="author">Feng, Fan, Huang, Biwei, Zhang, Kun, and Magliacane, Sara
          </div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>In Advances in Neural Information Processing Systems</em> Nov 2022
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a href="https://arxiv.org/abs/2203.16582" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">HTML</a>
            <a href="https://arxiv.org/pdf/2203.16582.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a>
            <a href="https://github.com/ffeng1996/Factored-Nonstationary-RL" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Code</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Dealing with non-stationarity in environments (e.g., in the transition dynamics) and objectives (e.g., in the reward functions) is a challenging problem that is crucial in real-world applications of reinforcement learning (RL). While most current approaches model the changes as a single shared embedding vector, we leverage insights from the recent causality literature to model non-stationarity in terms of individual latent change factors, and causal graphs across different environments. In particular, we propose Factored Adaptation for Non-Stationary RL (FANS-RL), a factored adaption approach that learns jointly both the causal structure in terms of a factored MDP, and a factored representation of the individual time-varying change factors. We prove that under standard assumptions, we can completely recover the causal graph representing the factored transition and reward function, as well as a partial structure between the individual change factors and the state components. Through our general framework, we can consider general non-stationary scenarios with different function types and changing frequency, including changes across episodes and within episodes. Experimental results demonstrate that FANS-RL outperforms existing approaches in terms of return, compactness of the latent state representation, and robustness to varying degrees of non-stationarity.</p>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge">NeurIPS</abbr></div>

        <!-- Entry bib key -->
        <div id="gagrani2022neural" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">Neural Topological Ordering for Computation Graphs</div>
          <!-- Author -->
          <div class="author">Gagrani, Mukul, Rainone, Corrado, Yang, Yang, Teague, Harris, Jeon, Wonseok, Hoof, Herke, Zeng, Weiliang Will, Zappi, Piero, Lott, Christopher, and Bondesan, Roberto
          </div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>In Advances in Neural Information Processing Systems</em> Nov 2022
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a href="https://arxiv.org/abs/2207.05899" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">HTML</a>
            <a href="https://arxiv.org/pdf/2207.05899" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a>
          </div>

          
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge">ICML</abbr></div>

        <!-- Entry bib key -->
        <div id="hoogeboom2022equivariant" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">Equivariant diffusion for molecule generation in 3d</div>
          <!-- Author -->
          <div class="author">Hoogeboom, Emiel, Satorras, Vı́ctor Garcia, Vignac, Clément, and Welling, Max
          </div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>In International Conference on Machine Learning</em> Nov 2022
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a href="https://arxiv.org/abs/2203.17003" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">HTML</a>
            <a href="https://arxiv.org/pdf/2203.17003" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a>
            <a href="https://github.com/ehoogeboom/e3_diffusion_for_molecules" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Code</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>This work introduces a diffusion model for molecule generation in 3D that is equivariant to Euclidean transformations. Our E(3) Equivariant Diffusion Model (EDM) learns to denoise a diffusion process with an equivariant network that jointly operates on both continuous (atom coordinates) and categorical features (atom types). In addition, we provide a probabilistic analysis which admits likelihood computation of molecules using our model. Experimentally, the proposed method significantly outperforms previous 3D molecular generative methods regarding the quality of generated samples and efficiency at training time.</p>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge">ICML</abbr></div>

        <!-- Entry bib key -->
        <div id="brandstetter2022lie" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">Lie Point Symmetry Data Augmentation for Neural PDE Solvers</div>
          <!-- Author -->
          <div class="author">Brandstetter, Johannes, Welling, Max, and Worrall, Daniel E
          </div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>In International Conference on Machine Learning</em> Nov 2022
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a href="https://arxiv.org/abs/2202.07643" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">HTML</a>
            <a href="https://arxiv.org/pdf/2202.07643" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a>
            <a href="https://github.com/brandstetter-johannes/LPSDA" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Code</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Neural networks are increasingly being used to solve partial differential equations (PDEs), replacing slower numerical solvers. However, a critical issue is that neural PDE solvers require high-quality ground truth data, which usually must come from the very solvers they are designed to replace. Thus, we are presented with a proverbial chicken-and-egg problem. In this paper, we present a method, which can partially alleviate this problem, by improving neural PDE solver sample complexity – Lie point symmetry data augmentation (LPSDA). In the context of PDEs, it turns out that we are able to quantitatively derive an exhaustive list of data transformations, based on the Lie point symmetry group of the PDEs in question, something not possible in other application areas. We present this framework and demonstrate how it can easily be deployed to improve neural PDE solver sample complexity by an order of magnitude.</p>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge">ICML</abbr></div>

        <!-- Entry bib key -->
        <div id="knigge2022sepconv" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">Exploiting Redundancy: Separable Group Convolutional Networks on Lie Groups</div>
          <!-- Author -->
          <div class="author">Knigge, David M, Romero, David W, and Bekkers, Erik J
          </div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>International Conference on Machine Learning</em> Nov 2022
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a href="https://arxiv.org/abs/2110.13059" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">HTML</a>
            <a href="https://arxiv.org/pdf/2110.13059.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a>
            <a href="https://github.com/david-knigge/separable-group-convolutional-networks" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Code</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Group convolutional neural networks (G-CNNs) have been shown to increase parameter efficiency and model accuracy by incorporating geometric inductive biases. In this work, we investigate the properties of representations learned by regular G-CNNs, and show considerable parameter redundancy in group convolution kernels. This finding motivates further weight-tying by sharing convolution kernels over subgroups. To this end, we introduce convolution kernels that are separable over the subgroup and channel dimensions. In order to obtain equivariance to arbitrary affine Lie groups we provide a continuous parameterisation of separable convolution kernels. We evaluate our approach across several vision datasets, and show that our weight sharing leads to improved performance and computational efficiency. In many settings, separable G-CNNs outperform their non-separable counterpart, while only using a fraction of their training time. In addition, thanks to the increase in computational efficiency, we are able to implement G-CNNs equivariant to the Sim(2) group; the group of dilations, rotations and translations. Sim(2)-equivariance further improves performance on all tasks considered.</p>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge">ICML</abbr></div>

        <!-- Entry bib key -->
        <div id="lippe2022citris" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">CITRIS: Causal Identifiability from Temporal Intervened Sequences</div>
          <!-- Author -->
          <div class="author">Lippe, Phillip, Magliacane, Sara, Löwe, Sindy, Asano, Yuki M, Cohen, Taco, and Gavves, Efstratios
          </div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>International Conference on Machine Learning</em> Nov 2022
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a href="https://arxiv.org/abs/2202.03169" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">HTML</a>
            <a href="https://arxiv.org/pdf/2202.03169.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a>
            <a href="https://github.com/phlippe/CITRIS" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Code</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Understanding the latent causal factors of a dynamical system from visual observations is a crucial step towards agents reasoning in complex environments. In this paper, we propose CITRIS, a variational autoencoder framework that learns causal representations from temporal sequences of images in which underlying causal factors have possibly been intervened upon. In contrast to the recent literature, CITRIS exploits temporality and observing intervention targets to identify scalar and multidimensional causal factors, such as 3D rotation angles. Furthermore, by introducing a normalizing flow, CITRIS can be easily extended to leverage and disentangle representations obtained by already pretrained autoencoders. Extending previous results on scalar causal factors, we prove identifiability in a more general setting, in which only some components of a causal factor are affected by interventions. In experiments on 3D rendered image sequences, CITRIS outperforms previous methods on recovering the underlying causal variables. Moreover, using pretrained autoencoders, CITRIS can even generalize to unseen instantiations of causal factors, opening future research areas in sim-to-real generalization for causal representation learning.</p>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge">ICML</abbr></div>

        <!-- Entry bib key -->
        <div id="park2022learning" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">Learning Symmetric Embeddings for Equivariant World Models</div>
          <!-- Author -->
          <div class="author">Park, Jung Yeon, Biza, Ondrej, Zhao, Linfeng, Meent, Jan-Willem, and Walters, Robin
          </div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>In International Conference on Machine Learning</em> Nov 2022
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a href="https://arxiv.org/pdf/2204.11371.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Incorporating symmetries can lead to highly data-efficient and generalizable models by defining equivalence classes of data samples related by transformations. However, characterizing how transformations act on input data is often difficult, limiting the applicability of equivariant models. We propose learning symmetric embedding networks (SENs) that encode an input space (e.g. images), where we do not know the effect of transformations (e.g. rotations), to a feature space that transforms in a known manner under these operations. This network can be trained end-to-end with an equivariant task network to learn an explicitly symmetric representation. We validate this approach in the context of equivariant transition models with 3 distinct forms of symmetry. Our experiments demonstrate that SENs facilitate the application of equivariant networks to data with complex symmetry representations. Moreover, doing so can yield improvements in accuracy and generalization relative to both fully-equivariant and non-equivariant baselines.</p>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge">ICML</abbr></div>

        <!-- Entry bib key -->
        <div id="antoran2022adapting" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">Adapting the Linearised Laplace Model Evidence for Modern Deep Learning</div>
          <!-- Author -->
          <div class="author">Antoran, Javier, Janz, David, Allingham, James Urquhart, Daxberger, Erik, Barbano, Riccardo, Nalisnick, Eric, and Hernandez-Lobato, Jose Miguel
          </div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>In Proceedings of the 39th International Conference on Machine Learning</em> Nov 2022
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a href="https://arxiv.org/abs/2206.08900" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">HTML</a>
            <a href="https://edaxberger.github.io/papers/Adapting%20the%20Linearised%20Laplace%20Model%20Evidence%20for%20Modern%20Deep%20Learning.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>The linearised Laplace method for estimating model uncertainty has received renewed attention in the Bayesian deep learning community. The method provides reliable error bars and admits a closed-form expression for the model evidence, allowing for scalable selection of model hyperparameters. In this work, we examine the assumptions behind this method, particularly in conjunction with model selection. We show that these interact poorly with some now-standard tools of deep learning–stochastic approximation methods and normalisation layers–and make recommendations for how to better adapt this classic method to the modern setting. We provide theoretical support for our recommendations and validate them empirically on MLPs, classic CNNs, residual networks with and without normalisation layers, generative autoencoders and transformers.</p>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge">ICML</abbr></div>

        <!-- Entry bib key -->
        <div id="verma2022calibrated" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">Calibrated Learning to Defer with One-vs-All Classifiers</div>
          <!-- Author -->
          <div class="author">Verma, Rajeev, and Nalisnick, Eric
          </div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>In Proceedings of the 39th International Conference on Machine Learning</em> Nov 2022
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a href="https://arxiv.org/abs/2202.03673" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">HTML</a>
            <a href="https://arxiv.org/pdf/2202.03673" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>The learning to defer (L2D) framework has the potential to make AI systems safer. For a given input, the system can defer the decision to a human if the human is more likely than the model to take the correct action. We study the calibration of L2D systems, investigating if the probabilities they output are sound. We find that Mozannar &amp; Sontag’s (2020) multiclass framework is not calibrated with respect to expert correctness. Moreover, it is not even guaranteed to produce valid probabilities due to its parameterization being degenerate for this purpose. We propose an L2D system based on one-vs-all classifiers that is able to produce calibrated probabilities of expert correctness. Furthermore, our loss function is also a consistent surrogate for multiclass L2D, like Mozannar &amp; Sontag’s (2020). Our experiments verify that not only is our system calibrated, but this benefit comes at no cost to accuracy. Our model’s accuracy is always comparable (and often superior) to Mozannar &amp; Sontag’s (2020) model’s in tasks ranging from hate speech detection to galaxy classification to diagnosis of skin lesions.</p>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge">ICML</abbr></div>

        <!-- Entry bib key -->
        <div id="wang2022model" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">Model-based Meta Reinforcement Learning using Graph Structured Surrogate Models and Amortized Policy Search</div>
          <!-- Author -->
          <div class="author">Wang, Q., and Hoof, H.
          </div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>In International Conference on Machine Learning</em> Nov 2022
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a href="https://arxiv.org/abs/2102.08291" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Reinforcement learning is a promising paradigm for solving sequential decision-making problems, but low data efficiency and weak generalization across tasks are bottlenecks in real-world applications. Model-based meta reinforcement learning addresses these issues by learning dynamics and leveraging knowledge from prior experience. In this paper, we take a closer look at this framework and propose a new posterior sampling based approach that consists of a new model to identify task dynamics together with an amortized policy optimization step. We show that our model, called a graph structured surrogate model (GSSM), achieves competitive dynamics prediction performance with lower model complexity. Moreover, our approach in policy search is able to obtain high returns and allows fast execution by avoiding test-time policy gradient updates.</p>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge">CLeaR</abbr></div>

        <!-- Entry bib key -->
        <div id="lowe2022amortized" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">Amortized Causal Discovery: Learning to Infer Causal Graphs from Time-Series Data</div>
          <!-- Author -->
          <div class="author">Löwe, S., Madras, D., Zemel, R., and Welling, M.
          </div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>Causal Learning and Reasoning</em> Nov 2022
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a href="https://arxiv.org/abs/2006.10833" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">HTML</a>
            <a href="https://arxiv.org/pdf/2006.10833.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a>
            <a href="https://github.com/loeweX/AmortizedCausalDiscovery" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Code</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>On time-series data, most causal discovery methods fit a new model whenever they encounter samples from a new underlying causal graph. However, these samples often share relevant information which is lost when following this approach. Specifically, different samples may share the dynamics which describe the effects of their causal relations. We propose Amortized Causal Discovery, a novel framework that leverages such shared dynamics to learn to infer causal relations from time-series data. This enables us to train a single, amortized model that infers causal relations across samples with different underlying causal graphs, and thus leverages the shared dynamics information. We demonstrate experimentally that this approach, implemented as a variational model, leads to significant improvements in causal discovery performance, and show how it can be extended to perform well under added noise and hidden confounding.</p>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge">ICLR</abbr></div>

        <!-- Entry bib key -->
        <div id="brandstetter2022geometric" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">Geometric and Physical Quantities improve E (3) Equivariant Message Passing</div>
          <!-- Author -->
          <div class="author">Brandstetter, Johannes, Hesselink, Rob, Pol, Elise, Bekkers, Erik, and Welling, Max
          </div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>In International Conference on Learning Representations</em> Nov 2022
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a href="https://openreview.net/forum?id=_xwr8gOBeV1" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">HTML</a>
            <a href="https://arxiv.org/pdf/2110.02905" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a>
            <a href="https://github.com/RobDHess/Steerable-E3-GNN" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Code</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Including covariant information, such as position, force, velocity or spin is important in many tasks in computational physics and chemistry. We introduce Steerable E(3) Equivariant Graph Neural Networks (SEGNNs) that generalise equivariant graph networks, such that node and edge attributes are not restricted to invariant scalars, but can contain covariant information, such as vectors or tensors. This model, composed of steerable MLPs, is able to incorporate geometric and physical information in both the message and update functions. Through the definition of steerable node attributes, the MLPs provide a new class of activation functions for general use with steerable feature fields. We discuss ours and related work through the lens of equivariant non-linear convolutions, which further allows us to pin-point the successful components of SEGNNs: non-linear message aggregation improves upon classic linear (steerable) point convolutions; steerable messages improve upon recent equivariant graph networks that send invariant messages. We demonstrate the effectiveness of our method on several tasks in computational physics and chemistry and provide extensive ablation studies.</p>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge">ICLR</abbr></div>

        <!-- Entry bib key -->
        <div id="ruhe2022selfsupervised" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">Self-Supervised Inference in State-Space Models</div>
          <!-- Author -->
          <div class="author">Ruhe, David, and Forré, Patrick
          </div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>In International Conference on Learning Representations</em> Nov 2022
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a href="https://openreview.net/forum?id=VPjw9KPWRSK" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">HTML</a>
            <a href="https://openreview.net/pdf?id=VPjw9KPWRSK" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>We perform approximate inference in state-space models with nonlinear state transitions. Without parameterizing a generative model, we apply Bayesian update formulas using a local linearity approximation parameterized by neural networks. It comes accompanied by a maximum likelihood objective that requires no supervision via uncorrupt observations or ground truth latent states. The optimization backpropagates through a recursion similar to the classical Kalman filter and smoother. Additionally, using an approximate conditional independence, we can perform smoothing without having to parameterize a separate model. In scientific applications, domain knowledge can give a linear approximation of the latent transition maps, which we can easily incorporate into our model. Usage of such domain knowledge is reflected in excellent results (despite our model’s simplicity) on the chaotic Lorenz system compared to fully supervised and variational inference methods. Finally, we show competitive results on an audio denoising experiment.</p>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge">ASCOM</abbr></div>

        <!-- Entry bib key -->
        <div id="ruhe2022detecting" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">Detecting dispersed radio transients in real time using convolutional neural networks</div>
          <!-- Author -->
          <div class="author">Ruhe, David, Kuiack, Mark, Rowlinson, Antonia, Wijers, Ralph, and Forré, Patrick
          </div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>Astronomy and Computing</em> Nov 2022
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a href="https://www.sciencedirect.com/science/article/pii/S2213133721000664" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">HTML</a>
            <a href="https://arxiv.org/pdf/2103.15418.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a>
          </div>

          
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge">ICLR</abbr></div>

        <!-- Entry bib key -->
        <div id="pol2022multi" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">Multi-Agent MDP Homomorphic Networks</div>
          <!-- Author -->
          <div class="author">Pol, Elise, Hoof, Herke, Oliehoek, Frans, and Welling, Max
          </div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>In International Conference on Learning Representations</em> Nov 2022
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a href="https://openreview.net/forum?id=H7HDG\hyphen\hyphenDJF0" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">HTML</a>
            <a href="https://openreview.net/pdf?id=H7HDG\hyphen\hyphenDJF0" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>This paper introduces Multi-Agent MDP Homomorphic Networks, a class of networks that allows distributed execution using only local information, yet is able to share experience between global symmetries in the joint state-action space of cooperative multi-agent systems. In cooperative multi-agent systems, complex symmetries arise between different configurations of the agents and their local observations. For example, consider a group of agents navigating: rotating the state globally results in a permutation of the optimal joint policy. Existing work on symmetries in single agent reinforcement learning can only be generalized to the fully centralized setting, because such approaches rely on the global symmetry in the full state-action spaces, and these can result in correspondences across agents. To encode such symmetries while still allowing distributed execution we propose a factorization that decomposes global symmetries into local transformations. Our proposed factorization allows for distributing the computation that enforces global symmetries over local agents and local interactions. We introduce a multi-agent equivariant policy network based on this factorization. We show empirically on symmetric multi-agent problems that globally symmetric distributable policies improve data efficiency compared to non-equivariant baselines.</p>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge">CPAIOR</abbr></div>

        <!-- Entry bib key -->
        <div id="kool2022deep" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">Deep Policy Dynamic Programming for Vehicle Routing Problems</div>
          <!-- Author -->
          <div class="author">Kool, Wouter, Hoof, Herke, Gromicho, Joaquim, and Welling, Max
          </div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>In International Conference on the Integration of Constraint Programming, Artificial Intelligence, and Operations Research</em> Nov 2022
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a href="https://arxiv.org/pdf/2102.11756" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a>
            <a href="https://github.com/wouterkool/dpdp" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Code</a>
          </div>

          
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge">AAAI</abbr></div>

        <!-- Entry bib key -->
        <div id="long2022fast" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">Fast and Data Efficient Reinforcement Learning from Pixels via Non-Parametric Value Approximation</div>
          <!-- Author -->
          <div class="author">Long, Alex, Blair, Alan, and Hoof, Herke
          </div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>In AAAI National Conference on Artificial Intelligence</em> Nov 2022
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a href="" class="btn btn-sm z-depth-0" role="button">HTML</a>
            <a href="https://www.aaai.org/AAAI22Papers/AAAI-8450.LongA.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a>
          </div>

          
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge">IJCAI</abbr></div>

        <!-- Entry bib key -->
        <div id="wohlke2022value" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">Value Refinement Network (VRN)</div>
          <!-- Author -->
          <div class="author">Wöhlke, Jan, Schmitt, Felix, and Hoof, Herke
          </div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>In International Joint Conference on Artificial Intelligence</em> Nov 2022
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a href="https://openreview.net/forum?id=iUt2KYdXBDD" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">HTML</a>
          </div>

          
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge">IJCAI</abbr></div>

        <!-- Entry bib key -->
        <div id="hopner2022leveraging" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">Leveraging class abstraction for commonsense reinforcement learning via residual policy gradient methods</div>
          <!-- Author -->
          <div class="author">Höpner, Niklas, Tiddi, Ilaria, and Hoof, Herke
          </div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>In International Joint Conference on Artificial Intelligence</em> Nov 2022
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a href="https://arxiv.org/abs/2201.12126" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">HTML</a>
            <a href="https://arxiv.org/pdf/2201.12126.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a>
          </div>

          
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge">MIDL</abbr></div>

        <!-- Entry bib key -->
        <div id="bakker2022multi" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">On learning adaptive acquisition policies for undersampled multi-coil MRI reconstruction</div>
          <!-- Author -->
          <div class="author">Bakker, T., Muckley, M., Romero-Soriano, A., Drozdzal, M., and Pineda, L.
          </div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>In Proceedings of Machine Learning Research</em> Jul 2022
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a href="https://arxiv.org/pdf/2203.16392.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a>
            <a href="https://github.com/facebookresearch/fastMRI" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Code</a>
          </div>

          
        </div>
      </div>
</li>
</ol>
          </div>


          <!-- Selected papers -->
          <div class="publications">
            <h2>Selected Publications</h2>
            <ol class="bibliography">
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge">NeurIPS</abbr></div>

        <!-- Entry bib key -->
        <div id="pol2020mdp" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">MDP Homomorphic Networks: Group Symmetries in Reinforcement Learning</div>
          <!-- Author -->
          <div class="author">Pol, Elise, Worrall, Daniel, Hoof, Herke, Oliehoek, Frans, and Welling, Max
          </div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>In Advances in Neural Information Processing Systems</em> 2020
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a href="https://proceedings.neurips.cc/paper/2020/hash/2be5f9c2e3620eb73c2972d7552b6cb5-Abstract.html" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">HTML</a>
            <a href="https://proceedings.neurips.cc/paper/2020/file/2be5f9c2e3620eb73c2972d7552b6cb5-Paper.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a>
          </div>

          
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge">ICLR</abbr></div>

        <!-- Entry bib key -->
        <div id="kool2020estimating" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">Estimating Gradients for Discrete Random Variables by Sampling without Replacement</div>
          <!-- Author -->
          <div class="author">Kool, Wouter, Hoof, Herke, and Welling, Max
          </div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>In International Conference on Learning Representations</em> 2020
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a href="https://openreview.net/forum?id=rklEj2EFvB" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">HTML</a>
            <a href="https://openreview.net/pdf?id=rklEj2EFvB" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a>
            <a href="https://github.com/wouterkool/estimating-gradients-without-replacement" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Code</a>
            <a href="https://youtu.be/KtP-Z2bvPPE" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Video</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>We derive an unbiased estimator for expectations over discrete random variables based on sampling without replacement, which reduces variance as it avoids duplicate samples. We show that our estimator can be derived as the Rao-Blackwellization of three different estimators. Combining our estimator with REINFORCE, we obtain a policy gradient estimator and we reduce its variance using a built-in control variate which is obtained without additional model evaluations. The resulting estimator is closely related to other gradient estimators. Experiments with a toy problem, a categorical Variational Auto-Encoder and a structured prediction problem show that our estimator is the only estimator that is consistently among the best estimators in both high and low entropy settings.</p>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge">ICLR</abbr></div>

        <!-- Entry bib key -->
        <div id="bekkers2019b" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">B-Spline CNNs on Lie groups</div>
          <!-- Author -->
          <div class="author">Bekkers, Erik J
          </div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>In International Conference on Learning Representations</em> 2019
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a href="https://openreview.net/forum?id=H1gBhkBFDH" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">HTML</a>
            <a href="https://openreview.net/pdf?id=H1gBhkBFDH" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a>
            <a href="https://github.com/ebekkers/gsplinets" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Code</a>
            <a href="https://www.youtube.com/watch?v=rakcnrgX4oo" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Video</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Group convolutional neural networks (G-CNNs) can be used to improve classical CNNs by equipping them with the geometric structure of groups. Central in the success of G-CNNs is the lifting of feature maps to higher dimensional disentangled representations, in which data characteristics are effectively learned, geometric data-augmentations are made obsolete, and predictable behavior under geometric transformations (equivariance) is guaranteed via group theory. Currently, however, the practical implementations of G-CNNs are limited to either discrete groups (that leave the grid intact) or continuous compact groups such as rotations (that enable the use of Fourier theory). In this paper we lift these limitations and propose a modular framework for the design and implementation of G-CNNs for arbitrary Lie groups. In our approach the differential structure of Lie groups is used to expand convolution kernels in a generic basis of B-splines that is defined on the Lie algebra. This leads to a flexible framework that enables localized, atrous, and deformable convolutions in G-CNNs by means of respectively localized, sparse and non-uniform B-spline expansions. The impact and potential of our approach is studied on two benchmark datasets: cancer detection in histopathology slides (PCam dataset) in which rotation equivariance plays a key role and facial landmark localization (CelebA dataset) in which scale equivariance is important. In both cases, G-CNN architectures outperform their classical 2D counterparts and the added value of atrous and localized group convolutions is studied in detail.</p>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge">AISTATS</abbr></div>

        <!-- Entry bib key -->
        <div id="esmaeili2018structured" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">Structured Disentangled Representations</div>
          <!-- Author -->
          <div class="author">Esmaeili, Babak, Wu, Hao, Jain, Sarthak, Bozkurt, Alican, Siddharth, N., Paige, Brooks, Brooks, Dana H., Dy, Jennifer, and van de Meent, Jan-Willem
          </div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>Artificial Intelligence and Statistics</em> 2019
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a href="https://proceedings.mlr.press/v89/esmaeili19a" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">HTML</a>
            <a href="https://proceedings.mlr.press/v89/esmaeili19a/esmaeili19a.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Deep latent-variable models learn representations of high-dimensional data in an unsupervised manner. A number of recent efforts have focused on learning representations that disentangle statistically independent axes of variation by introducing modifications to the standard objective function. These approaches generally assume a simple diagonal Gaussian prior and as a result are not able to reliably disentangle discrete factors of variation. We propose a two-level hierarchical objective to control relative degree of statistical independence between blocks of variables and individual variables within blocks. We derive this objective as a generalization of the evidence lower bound, which allows us to explicitly represent the trade-offs between mutual information between data and representation, KL divergence between representation and prior, and coverage of the support of the empirical data distribution. Experiments on a variety of datasets demonstrate that our objective can not only disentangle discrete variables, but that doing so also improves disentanglement of other variables and, importantly, generalization even to unseen combinations of factors.</p>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge">ICLR</abbr></div>

        <!-- Entry bib key -->
        <div id="nalisnick2018do" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">Do Deep Generative Models Know What They Don’t Know?</div>
          <!-- Author -->
          <div class="author">Nalisnick, Eric, Matsukawa, Akihiro, Teh, Yee Whye, Gorur, Dilan, and Lakshminarayanan, Balaji
          </div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>In International Conference on Learning Representations</em> 2019
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a href="https://openreview.net/forum?id=H1xwNhCcYm" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">HTML</a>
            <a href="https://openreview.net/pdf?id=H1xwNhCcYm" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a>
          </div>

          
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge">ESWC</abbr></div>

        <!-- Entry bib key -->
        <div id="schlichtkrull2018modeling" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">Modeling Relational Data with Graph Convolutional Networks</div>
          <!-- Author -->
          <div class="author">Schlichtkrull, Michael, Kipf, Thomas N., Bloem, Peter, Berg, Rianne, Titov, Ivan, and Welling, Max
          </div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>In The Semantic Web: 15th International Conference, ESWC 2018, Heraklion, Crete, Greece</em> 2018
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a href="https://link.springer.com/chapter/10.1007/978-3-319-93417-4_38" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">HTML</a>
            <a href="https://arxiv.org/pdf/1703.06103.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Knowledge graphs enable a wide variety of applications, including question answering and information retrieval. Despite the great effort invested in their creation and maintenance, even the largest (e.g., Yago, DBPedia or Wikidata) remain incomplete. We introduce Relational Graph Convolutional Networks (R-GCNs) and apply them to two standard knowledge base completion tasks: Link prediction (recovery of missing facts, i.e. subject-predicate-object triples) and entity classification (recovery of missing entity attributes). R-GCNs are related to a recent class of neural networks operating on graphs, and are developed specifically to handle the highly multi-relational data characteristic of realistic knowledge bases. We demonstrate the effectiveness of R-GCNs as a stand-alone model for entity classification. We further show that factorization models for link prediction such as DistMult can be significantly improved through the use of an R-GCN encoder model to accumulate evidence over multiple inference steps in the graph, demonstrating a large improvement of 29.8% on FB15k-237 over a decoder-only baseline.</p>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge">NeurIPS</abbr></div>

        <!-- Entry bib key -->
        <div id="siddharth_nips_2017" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">Learning Disentangled Representations with Semi-Supervised Deep Generative Models</div>
          <!-- Author -->
          <div class="author">Siddharth, N., Paige, Brooks, Meent, Jan-Willem, Desmaison, Alban, Goodman, Noah D., Kohli, Pushmeet, Wood, Frank, and Torr, Philip
          </div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>In Advances in Neural Information Processing Systems 30</em> 2017
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a href="https://proceedings.neurips.cc/paper/2017/hash/9cb9ed4f35cf7c2f295cc2bc6f732a84-Abstract.html" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">HTML</a>
            <a href="https://proceedings.neurips.cc/paper/2017/file/9cb9ed4f35cf7c2f295cc2bc6f732a84-Paper.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a>
            <a href="https://github.com/probtorch/probtorch" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Code</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Variational autoencoders (VAEs) learn representations of data by jointly training a probabilistic encoder and decoder network. Typically these models encode all features of the data into a single variable. Here we are interested in learning disentangled representations that encode distinct aspects of the data into separate variables. We propose to learn such representations using model architectures that generalise from standard VAEs, employing a general graphical model structure in the encoder and decoder. This allows us to train partially-specified models that make relatively strong assumptions about a subset of interpretable variables and rely on the flexibility of neural networks to learn representations for the remaining variables. We further define a general objective for semi-supervised learning in this model class, which can be approximated using an importance sampling procedure. We evaluate our framework’s ability to learn disentangled representations, both by qualitative exploration of its generative capacity, and quantitative evaluation of its discriminative ability on a variety of models and datasets.</p>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge">ICLR</abbr></div>

        <!-- Entry bib key -->
        <div id="kipf2016semi" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">Semi-supervised classification with graph convolutional networks</div>
          <!-- Author -->
          <div class="author">Kipf, Thomas N, and Welling, Max
          </div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>In International Conference on Learning Representations</em> 2017
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a href="https://openreview.net/forum?id=SJU4ayYgl" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">HTML</a>
            <a href="https://arxiv.org/pdf/1609.02907.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a>
          </div>

          
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge">ICML</abbr></div>

        <!-- Entry bib key -->
        <div id="pmlr-v48-cohenc16" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">Group Equivariant Convolutional Networks</div>
          <!-- Author -->
          <div class="author">Cohen, Taco, and Welling, Max
          </div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>In Proceedings of The 33rd International Conference on Machine Learning</em> 20–22 jun 2016
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a href="https://proceedings.mlr.press/v48/cohenc16.html" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">HTML</a>
            <a href="http://proceedings.mlr.press/v48/cohenc16.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>We introduce Group equivariant Convolutional Neural Networks (G-CNNs), a natural generalization of convolutional neural networks that reduces sample complexity by exploiting symmetries. G-CNNs use G-convolutions, a new type of layer that enjoys a substantially higher degree of weight sharing than regular convolution layers. G-convolutions increase the expressive capacity of the network without increasing the number of parameters. Group convolution layers are easy to use and can be implemented with negligible computational overhead for discrete groups generated by translations, reflections and rotations. G-CNNs achieve state of the art results on CIFAR10 and rotated MNIST.</p>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge">NeurIPS</abbr></div>

        <!-- Entry bib key -->
        <div id="NIPS2016_ddeebdee" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">Improved Variational Inference with Inverse Autoregressive Flow</div>
          <!-- Author -->
          <div class="author">Kingma, Durk P, Salimans, Tim, Jozefowicz, Rafal, Chen, Xi, Sutskever, Ilya, and Welling, Max
          </div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>In Advances in Neural Information Processing Systems</em> 20–22 jun 2016
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a href="https://proceedings.neurips.cc/paper/2016/hash/ddeebdeefdb7e7e7a697e1c3e3d8ef54-Abstract.html" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">HTML</a>
            <a href="https://proceedings.neurips.cc/paper/2016/file/ddeebdeefdb7e7e7a697e1c3e3d8ef54-Paper.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a>
          </div>

          
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge">NeurIPS</abbr></div>

        <!-- Entry bib key -->
        <div id="NIPS2014_d523773c" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">Semi-Supervised Learning with Deep Generative Models</div>
          <!-- Author -->
          <div class="author">Kingma, Durk P, Mohamed, Shakir, Jimenez Rezende, Danilo, and Welling, Max
          </div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>In Advances in Neural Information Processing Systems</em> 20–22 jun 2014
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a href="https://proceedings.neurips.cc/paper/2014/hash/d523773c6b194f37b938d340d5d02232-Abstract.html" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">HTML</a>
            <a href="https://proceedings.neurips.cc/paper/2014/file/d523773c6b194f37b938d340d5d02232-Paper.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a>
          </div>

          
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge">ICLR</abbr></div>

        <!-- Entry bib key -->
        <div id="kingma2013autoencoding" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">Auto-Encoding Variational Bayes</div>
          <!-- Author -->
          <div class="author">Kingma, Diederik P., and Welling, Max
          </div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em></em> 20–22 jun 2013
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a href="https://openreview.net/forum?id=33X9fd2-9FyZd" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">HTML</a>
            <a href="https://arxiv.org/pdf/1312.6114v10.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a>
          </div>

          
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge">ICML</abbr></div>

        <!-- Entry bib key -->
        <div id="welling2011bayesian" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">Bayesian learning via stochastic gradient langevin dynamics</div>
          <!-- Author -->
          <div class="author">Welling, Max, and Teh, Yee Whye
          </div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>In Proceedings of the 28th International Conference on Machine Learning, ICML 2011</em> 20–22 jun 2011
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a href="http://www.icml-2011.org/papers.php" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">HTML</a>
            <a href="http://www.icml-2011.org/papers/398_icmlpaper.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a>
            <a href="https://icml.cc/virtual/2021/test-of-time/11808" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Video</a>
          </div>

          
        </div>
      </div>
</li>
</ol>
          </div>

        </article>

</div>

    </div>

    <!-- Footer -->    
    <footer class="fixed-bottom">
      <div class="container mt-0">
        © Copyright 2025 AMLab  | Amsterdam Machine Learning Lab. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="noopener noreferrer">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" target="_blank" rel="noopener noreferrer">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="noopener noreferrer">GitHub Pages</a>.

      </div>
    </footer>

    <!-- JavaScripts -->
    <!-- jQuery -->
  <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script>

    <!-- Bootsrap & MDB scripts -->
  <script src="https://cdn.jsdelivr.net/npm/@popperjs/core@2.11.2/dist/umd/popper.min.js" integrity="sha256-l/1pMF/+J4TThfgARS6KwWrk/egwuVvhRzfLAMQ6Ds4=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.min.js" integrity="sha256-SyTu6CwrfOhaznYZPoolVw2rxoY7lKYKQvqbtqN93HI=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script>

    <!-- Masonry & imagesLoaded -->
  <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script>
  <script defer src="/assets/js/masonry.js" type="text/javascript"></script>
    
  <!-- Medium Zoom JS -->
  <script src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.6/dist/medium-zoom.min.js" integrity="sha256-EdPgYcPk/IIrw7FYeuJQexva49pVRZNmt3LculEr7zM=" crossorigin="anonymous"></script>
  <script src="/assets/js/zoom.js"></script><!-- Load Common JS -->
  <script src="/assets/js/common.js"></script>

    <!-- MathJax -->
  <script type="text/javascript">
    window.MathJax = {
      tex: {
        tags: 'ams'
      }
    };
  </script>
  <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script>
  <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>

    
  </body>
</html>

